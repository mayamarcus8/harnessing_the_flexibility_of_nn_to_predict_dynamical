{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f056df89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "from qp_fit import *\n",
    "from qp_pred import *\n",
    "from utils import *\n",
    "\n",
    "import warnings\n",
    "import multiprocessing as mp\n",
    "import time\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a8a0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload data \n",
    "df = pd.read_csv('../data/for_plos.csv')\n",
    "df = df.rename(columns={'key':'action'})\n",
    "\n",
    "df.loc[df[\"action\"] == \"R1\", \"action\"] = 0\n",
    "df.loc[df[\"action\"] == \"R2\", \"action\"] = 1\n",
    "\n",
    "df['action'] = df['action'].astype(int)\n",
    "df['reward'] = df['reward'].astype(int)\n",
    "df['block'] = df['block'] - 1\n",
    "\n",
    "# create unique list of names\n",
    "UniqueNames = df.ID.unique()\n",
    "dic = {}\n",
    "for i in range(101):\n",
    "    dic[UniqueNames[i]] = i\n",
    "for i in range(101):\n",
    "    df.loc[df.ID == UniqueNames[i], 'ID'] = dic[UniqueNames[i]]\n",
    "df = df.rename(columns={'ID':'subject'}).copy()\n",
    "\n",
    "label = []\n",
    "for i in range(101):\n",
    "    if 'B' in df[df.subject==i].diag.values[0]:\n",
    "        label.append(0)\n",
    "    elif 'D' in df[df.subject==i].diag.values[0]:\n",
    "        label.append(1)\n",
    "    else:\n",
    "        label.append(2)    \n",
    "z = []\n",
    "b = []\n",
    "d = []\n",
    "h = []\n",
    "idx = [] \n",
    "\n",
    "for i in range(101):\n",
    "    if label[i] == 0:\n",
    "        b.append(df[df.subject==i]) \n",
    "    elif label[i] == 1:\n",
    "        d.append(df[df.subject==i])\n",
    "    else:\n",
    "        h.append(df[df.subject==i])\n",
    "       \n",
    "        \n",
    "for i in range(len(b)):\n",
    "    z.append(b[i])\n",
    "    idx.append(np.repeat(i,len(b[i])))\n",
    "    \n",
    "last_i = i+1\n",
    "    \n",
    "for i in range(len(d)):\n",
    "    z.append(d[i])\n",
    "    idx.append(np.repeat(last_i+i,len(d[i])))\n",
    "\n",
    "last_i = last_i+i+1\n",
    "\n",
    "for i in range(len(h)):\n",
    "    z.append(h[i])\n",
    "    idx.append(np.repeat(last_i+i,len(h[i])))\n",
    "\n",
    "df = pd.concat(z).reset_index().drop(columns='index')\n",
    "df['subject'] = np.concatenate(idx)\n",
    "\n",
    "\n",
    "all_data = []\n",
    "n_trials = []\n",
    "\n",
    "for i in range(101):\n",
    "    cur_df = df[(df['subject']==i)].reset_index()\n",
    "    all_data.append(cur_df)\n",
    "    n_trials.append(len(cur_df))\n",
    "\n",
    "bipolar_data = df[df.subject<33]\n",
    "depression_data = df[(df.subject>=33) & (df.subject<67)]\n",
    "healthy_data = df[(df.subject>=67)]\n",
    "\n",
    "# fit parameters of all subj \n",
    "fit_arr = []\n",
    "for i in range(101):    \n",
    "    pool = mp.Pool(processes=mp.cpu_count())\n",
    "    temp_fit_arr = pool.map(qp_fit,[all_data[i],all_data[i],all_data[i],all_data[i],all_data[i]])\n",
    "    pool.close()\n",
    "    x = np.array([temp_fit_arr[j].fun for j in range(5)])\n",
    "    fit_arr.append(temp_fit_arr[np.argmin(x)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff2361c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred all subj actions\n",
    "\n",
    "def bce_loss(y_hat,y_true):\n",
    "    eps = 1e-10\n",
    "    return (-((y_true*(np.log(y_hat + eps)) + (1-y_true)*(np.log(1-y_hat + eps)))))\n",
    "\n",
    "bce_arr = []\n",
    "p_r2_arr = []\n",
    "all_p_0 = []\n",
    "norm_ll_arr = []\n",
    "for i in range(101):\n",
    "    \n",
    "    cur_df = df[(df['subject']==i)].reset_index()\n",
    "    acc,p_0 = qp_pred(cur_df,fit_arr[i].x)\n",
    "    \n",
    "    all_p_0.append(p_0)\n",
    "    loss = bce_loss(1-p_0, cur_df.action.values)\n",
    "    bce_arr.append(loss.mean())\n",
    "    p_r2_arr.append( 1- (np.array(loss.sum()) / (-len(cur_df)*np.log(0.5))))\n",
    "    norm_ll_arr.append(np.exp(-loss.mean()))\n",
    "    \n",
    "ind_alpha = np.array([fit_arr[i].x[0] for i in range(101)])\n",
    "ind_beta = np.array([fit_arr[i].x[1] for i in range(101)])\n",
    "ind_kappa = np.array([fit_arr[i].x[2] for i in range(101)])\n",
    "ind_ntrials = np.array(n_trials)\n",
    "ind_nll = np.array([fit_arr[i].fun for i in range(101)])\n",
    "subj = np.arange(101)\n",
    "\n",
    "diag = np.concatenate([np.repeat(df.diag.unique()[0],33),\n",
    "        np.repeat(df.diag.unique()[1],34),\n",
    "        np.repeat(df.diag.unique()[2],34)])\n",
    "\n",
    "# save files\n",
    "pd.DataFrame({'subject':subj,\n",
    "              'diag':diag,\n",
    "              'alpha':ind_alpha,\n",
    "              'beta':ind_beta,\n",
    "              'kappa':ind_kappa,\n",
    "              'nll':ind_nll,\n",
    "              'n_trials':ind_ntrials,\n",
    "              'bce':bce_arr,\n",
    "              'psr2':p_r2_arr,\n",
    "              'norm_ll':norm_ll_arr}).to_csv('../results/dezfouli_individual_theoretical.csv',index=False)\n",
    "\n",
    "with open('../results/dezfouli_individual_p_0_theoretical.pickle', 'wb') as handle:\n",
    "    pickle.dump(all_p_0, handle, protocol=pickle.HIGHEST_PROTOCOL)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
