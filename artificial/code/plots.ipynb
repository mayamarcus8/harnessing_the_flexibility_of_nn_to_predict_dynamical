{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b54b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import Line2D\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from bayesian_fit import *\n",
    "from q_pred_ns import *\n",
    "from q_fit import *\n",
    "from q_pred import * \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3111905b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss functions\n",
    "def BCE_loss(y_hat,y_true):\n",
    "    eps = 1e-10\n",
    "    return (-((y_true*(np.log(y_hat + eps)) + (1-y_true)*(np.log(1-y_hat + eps)))))\n",
    "\n",
    "def MSE_loss(y_true,y_hat):\n",
    "    return ((y_hat - y_true)**2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5821954b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read test data \n",
    "df = pd.read_csv('../data/artificial_testset.csv')\n",
    "\n",
    "num_of_agent = df['agent'].nunique() \n",
    "num_of_action = df['action'].nunique()\n",
    "num_of_trials = df['trial'].nunique()\n",
    "\n",
    "all_data = []\n",
    "\n",
    "for i in range(num_of_agent):\n",
    "    cur_df = df[(df['agent']==i)].reset_index()\n",
    "    all_data.append(cur_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9856c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit q-stationary\n",
    "\n",
    "all_p_0_qs = []\n",
    "bce_arr_qs = []\n",
    "p_r2_arr_qs = []\n",
    "norm_ll_arr_qs = []\n",
    "\n",
    "alpha_qs, beta_qs = [],[]\n",
    "mse_alpha_qs, mse_beta_qs = [],[]\n",
    "\n",
    "for i in range(num_of_agent):\n",
    "    \n",
    "    res = q_fit(all_data[i])\n",
    "    acc,p_0 = q_pred(all_data[i],res.x)\n",
    "    \n",
    "    all_p_0_qs.append(p_0)\n",
    "    alpha_qs.append(res.x[0])\n",
    "    beta_qs.append(res.x[1])\n",
    "    \n",
    "    loss = BCE_loss(1 - p_0, all_data[i].action.values)\n",
    "    bce_arr_qs.append(loss.mean())\n",
    "    p_r2_arr_qs.append( 1 - (np.array(loss.sum()) / (-len(all_data[i])*np.log(0.5))))\n",
    "    norm_ll_arr_qs.append(np.exp(-loss.mean()))\n",
    "    \n",
    "    mse_alpha_qs.append((MSE_loss(all_data[i]['alpha']    , np.repeat(alpha_qs[i]   ,num_of_trials) ) ))\n",
    "    mse_beta_qs.append((MSE_loss(all_data[i]['beta']/10  ,  np.repeat(beta_qs[i]/10 ,num_of_trials) ) ))\n",
    "    \n",
    "print('QS BCE '       , np.array(bce_arr_qs).mean()   )\n",
    "print('QS PR2'       , np.array(p_r2_arr_qs).mean()   )\n",
    "print('QS MSE alpha ' , np.array(mse_alpha_qs).mean() )\n",
    "print('QS MSE beta '  , np.array(mse_beta_qs).mean()  )\n",
    "\n",
    "print('===================')\n",
    "\n",
    "print('QS BCE std '       , np.array(bce_arr_qs).std()   )\n",
    "print('QS PR2 std'       , np.array(p_r2_arr_qs).std()   )\n",
    "print('QS MSE alpha std ' , np.array(mse_alpha_qs).std() )\n",
    "print('QS MSE beta std'  , np.array(mse_beta_qs).std()  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1709688",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit bayesian\n",
    "w = []\n",
    "for i in range(num_of_agent):\n",
    "    obs = all_data[i][['action','reward']].values\n",
    "    w.append(bayesian_fit(obs))\n",
    "\n",
    "alpha_bay = [ 1 / (1 + np.exp(-w[i][0][:,2])) for i in range(num_of_agent) ]\n",
    "beta_bay =  [ (np.exp(w[i][0][:,3])).clip(0,10) for i in range(num_of_agent) ]\n",
    "\n",
    "all_p_0_bay = []\n",
    "bce_arr_bay = []\n",
    "p_r2_arr_bay = []\n",
    "norm_ll_arr_bay = []\n",
    "\n",
    "mse_alpha_bay, mse_beta_bay = [],[]\n",
    "\n",
    "for i in range(num_of_agent):\n",
    "        \n",
    "    pp = np.array([alpha_bay[i],beta_bay[i]]).T\n",
    "\n",
    "    acc,p_0 = q_pred_ns(all_data[i],pp)\n",
    "    all_p_0_bay.append(p_0)\n",
    "    \n",
    "    loss = BCE_loss(1 - p_0, all_data[i].action.values)\n",
    "    bce_arr_bay.append(loss.mean())\n",
    "    p_r2_arr_bay.append( 1 - (np.array(loss.sum()) / (-len(all_data[i])*np.log(0.5))))\n",
    "    norm_ll_arr_bay.append(np.exp(-loss.mean()))\n",
    "    \n",
    "    mse_alpha_bay.append((MSE_loss(all_data[i]['alpha']    , alpha_bay[i]   ) ))\n",
    "    mse_beta_bay.append((MSE_loss(all_data[i]['beta']/10  , beta_bay[i]/10  ) ))\n",
    "    \n",
    "print('BAY BCE '       , np.array(bce_arr_bay).mean()   )\n",
    "print('BAY PR2 '       , np.array(p_r2_arr_bay).mean()   )\n",
    "print('BAY MSE alpha ' , np.array(mse_alpha_bay).mean() )\n",
    "print('BAY MSE beta '  , np.array(mse_beta_bay).mean()  )\n",
    "\n",
    "print('===================')\n",
    "\n",
    "print('BAY BCE std '       , np.array(bce_arr_bay).std()   )\n",
    "print('BAY PR2 std'       , np.array(p_r2_arr_bay).std()   )\n",
    "print('BAY MSE alpha std ' , np.array(mse_alpha_bay).std() )\n",
    "print('BAY MSE beta std'  , np.array(mse_beta_bay).std()  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf0f9e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRU_RNN_TWO(nn.Module):\n",
    "        \n",
    "    def __init__(self,input_size, hidden_size, num_of_layers, num_alpha_embedding, num_beta_embedding, output_size, dropout):\n",
    "        \n",
    "        super(GRU_RNN_TWO, self).__init__()\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.num_alpha_embedding = num_alpha_embedding\n",
    "        self.num_beta_embedding = num_beta_embedding        \n",
    "        \n",
    "        self.hidden_0 = nn.GRU(  \n",
    "                    input_size=input_size,\n",
    "                    hidden_size=hidden_size,\n",
    "                    num_layers=num_of_layers,\n",
    "                    batch_first=True,\n",
    "                    dropout=dropout\n",
    "        )\n",
    "        \n",
    "        self.hidden_1 = nn.GRU(  \n",
    "                    input_size=input_size + num_alpha_embedding + num_beta_embedding,\n",
    "                    hidden_size=hidden_size,\n",
    "                    num_layers=num_of_layers,\n",
    "                    batch_first=True,\n",
    "                    dropout=dropout \n",
    "        )\n",
    "    \n",
    "        \n",
    "        self.out_alpha = nn.Linear(hidden_size, num_alpha_embedding)\n",
    "        self.out_beta = nn.Linear(hidden_size, num_beta_embedding)\n",
    "        \n",
    "        self.relu_alpha = nn.ReLU()\n",
    "        self.relu_beta = nn.ReLU()\n",
    "\n",
    "        self.reg_alpha = nn.Linear(num_alpha_embedding, 1)\n",
    "        self.reg_beta = nn.Linear(num_beta_embedding, 1)\n",
    "\n",
    "        \n",
    "        self.out_action = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "\n",
    "        # parameters estimation\n",
    "        output_0, hn_0 = self.hidden_0(x)\n",
    "        \n",
    "        output_alpha = self.out_alpha(output_0)\n",
    "        output_alpha = self.relu_alpha(output_alpha)\n",
    "        \n",
    "        output_beta = self.out_beta(output_0)\n",
    "        output_beta = self.relu_beta(output_beta)\n",
    "        \n",
    "        cont_output_alpha = self.reg_alpha(output_alpha)\n",
    "        cont_output_beta = self.reg_beta(output_beta)\n",
    "    \n",
    "        # concat input \n",
    "        input_1 = torch.cat([x[0],output_alpha[0],output_beta[0]],dim=1) # cat # concat\n",
    "        input_1 = input_1.reshape(1,x.shape[1],self.input_size + self.num_alpha_embedding\n",
    "                                  + self.num_beta_embedding)\n",
    "        \n",
    "        # action predication\n",
    "        output_action, hn_1 = self.hidden_1(input_1)\n",
    "        output_action = self.out_action(output_action)\n",
    "        output_action = F.softmax(output_action,dim=-1)\n",
    "        \n",
    "        output_dis = [output_alpha, output_beta]\n",
    "        output_cont = [cont_output_alpha, cont_output_beta]\n",
    "\n",
    "        return output_dis, output_cont, output_action, hn_0, hn_1\n",
    "    \n",
    "\n",
    "\n",
    "class behavior_dataset(Dataset):\n",
    "    \"\"\" \n",
    "    Transform Dataframe of an agent to torch Dataset class \n",
    "    \n",
    "    Args:\n",
    "        dataframe: pandas dataframe of agent behavior \n",
    "        n_parameters_embedding: number of parameters embedding class\n",
    "        \n",
    "    Returns: \n",
    "        torch Dataset:\n",
    "        x: [reward_(t-1) , action_(t-1)] action are encoded as one-hot vectors\n",
    "        y: [action_t, parameter embedding] action and parameters are encoded as one-hot vectors\n",
    "        \n",
    "    \"\"\"\n",
    "    def __init__(self,dataframe):\n",
    "        \n",
    "        # action one hot transformation \n",
    "        action = np.array(dataframe['action'])\n",
    "        if np.all(action == action[0]):\n",
    "            action = np.append(action,(1-action[0]))\n",
    "            action = torch.tensor((action).reshape(len(dataframe) + 1),dtype=int)\n",
    "            action_onehot = nn.functional.one_hot(action, len(action.unique()))\n",
    "            # delete last one\n",
    "            action_onehot = action_onehot[:-1]\n",
    "        else:\n",
    "            action = torch.tensor((action).reshape(len(dataframe)),dtype=int)\n",
    "            action_onehot = nn.functional.one_hot(action, len(action.unique()))\n",
    "        \n",
    "        # reward\n",
    "        reward = torch.tensor((np.array(dataframe['reward'])).reshape(len(dataframe)),dtype=int)\n",
    "        \n",
    "        # concatinating reward and action\n",
    "        reward_action = torch.cat([reward[ :, np.newaxis], action_onehot],1)\n",
    "        \n",
    "        # adding dummy zeros to the beginning and ignoring the last one\n",
    "        reward_action_shift = nn.functional.pad(reward_action,[0,0,1,0])[:-1]\n",
    "        \n",
    "        # network input \n",
    "        x = reward_action_shift\n",
    "        \n",
    "#         n_blocks = int(len(dataframe)/100)\n",
    "#         x.reshape(n_blocks,100,3)[:,0,:] = torch.zeros(size=(n_blocks,3))\n",
    "    \n",
    "        y = action_onehot\n",
    "  \n",
    "        self.x = x.type(dtype=torch.float32)\n",
    "        self.y = y.type(dtype=torch.float32)\n",
    "        self.len = len(dataframe)\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        return self.x[idx],self.y[idx]\n",
    "  \n",
    "    def __len__(self):\n",
    "        return self.len    \n",
    "    \n",
    "class merge_behavior_dataset(Dataset):\n",
    "    \"\"\" \n",
    "    Merge Dataset of each agent to one dataset\n",
    "    \n",
    "    Args:\n",
    "        dataset_list: list of Dataset of all agent \n",
    "        n_trials: num_of_trials each agent was simulated\n",
    "        \n",
    "    Returns: \n",
    "        torch Dataset:\n",
    "        x: [reward_(t-1) , action_(t-1)] all agents\n",
    "        y: [action_t, parameter embedding] all agents\n",
    "        \n",
    "    \"\"\"\n",
    "    def __init__(self, dataset_list, n_trials):\n",
    "        X = []\n",
    "        Y = []\n",
    "        for j,agent in enumerate(dataset_list):\n",
    "            for i in range(n_trials[j]):\n",
    "                X.append(agent[i][0])\n",
    "                Y.append(agent[i][1])\n",
    "                \n",
    "        self.x = torch.stack(X).type(dtype=torch.float32)\n",
    "        self.y = torch.stack(Y).type(dtype=torch.float32)\n",
    "        self.len = len(X)   \n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        return self.x[idx],self.y[idx]\n",
    "  \n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "    \n",
    "all_data_rnn = []\n",
    "\n",
    "for i in range(num_of_agent):\n",
    "    cur_df = all_data[i]\n",
    "    cur_df = cur_df.reset_index()\n",
    "    all_data_rnn.append(behavior_dataset(cur_df))\n",
    "    \n",
    "val_dataset = merge_behavior_dataset(all_data_rnn, np.repeat(num_of_trials,num_of_agent))\n",
    "\n",
    "load = torch.load(f'checkpoint/checkpoint_trnn_5.pth',map_location='cpu')\n",
    "\n",
    "INPUT_SIZE = 3\n",
    "aHidden = 32\n",
    "num_alpha_embedding = 5\n",
    "num_beta_embedding = 5\n",
    "OUTPUT_SIZE = 2\n",
    "\n",
    "rnn = GRU_RNN_TWO(\n",
    "              input_size=INPUT_SIZE,\n",
    "              hidden_size=aHidden,\n",
    "              num_of_layers=1,\n",
    "              num_alpha_embedding=num_alpha_embedding,\n",
    "              num_beta_embedding=num_beta_embedding,\n",
    "              output_size=OUTPUT_SIZE,\n",
    "              dropout=0\n",
    "            )\n",
    "\n",
    "rnn.load_state_dict(load['model_state'])\n",
    "print(load['epoch'])\n",
    "rnn.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dff99e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_trnn = []\n",
    "beta_trnn = []\n",
    "all_p_0_trnn = []\n",
    "\n",
    "j = 0\n",
    "\n",
    "for i in range(num_of_agent):\n",
    "        \n",
    "    cur_df = all_data[i]\n",
    "    \n",
    "    num_of_trials = len(cur_df)\n",
    "        \n",
    "    y_hat_dis, y_hat_cont, y_hat_action, _, _ = rnn((val_dataset[j:num_of_trials+j][0].reshape(1,num_of_trials,3)))\n",
    "    y_hat_action = (y_hat_action.view(-1, num_of_action)) \n",
    "    \n",
    "    alpha_trnn.append((y_hat_cont[0].cpu().detach().numpy().flatten()))    \n",
    "    beta_trnn.append((y_hat_cont[1].cpu().detach().numpy().flatten()))\n",
    "    all_p_0_trnn.append(((y_hat_action[:,0]).cpu().detach().numpy()))\n",
    "    \n",
    "    j += num_of_trials\n",
    "    \n",
    "bce_arr_trnn = []\n",
    "p_r2_arr_trnn = []\n",
    "norm_ll_arr_trnn = []\n",
    "mse_alpha_trnn, mse_beta_trnn = [],[]\n",
    "\n",
    "for i in range(num_of_agent):\n",
    "    bce = BCE_loss(1-all_p_0_trnn[i],all_data[i]['action'])\n",
    "    bce_arr_trnn.append(bce.mean())\n",
    "    p_r2_arr_trnn.append(1-(np.array(bce.sum()) / (-len(all_data[i])*np.log(0.5))))\n",
    "    norm_ll_arr_trnn.append(np.exp(-bce.mean()))\n",
    "    mse_alpha_trnn.append( ( MSE_loss(all_data[i]['alpha']   ,alpha_trnn[i]      ) ))\n",
    "    mse_beta_trnn.append(  ( MSE_loss(all_data[i]['beta']/10 ,beta_trnn[i]/10   ) ))\n",
    "    \n",
    "print('tRNN BCE '       , np.array(bce_arr_trnn).mean()   )\n",
    "print('tRNN PR2 '       , np.array(p_r2_arr_trnn).mean()   )\n",
    "print('tRNN MSE alpha ' , np.array(mse_alpha_trnn).mean() )\n",
    "print('tRNN MSE beta '  , np.array(mse_beta_trnn).mean()  )\n",
    "\n",
    "print('===================')\n",
    "\n",
    "print('tRNN BCE std '       , np.array(bce_arr_trnn).std()   )\n",
    "print('tRNN PR2 std '       , np.array(p_r2_arr_trnn).std()   )\n",
    "print('tRNN MSE alpha std ' , np.array(mse_alpha_trnn).std() )\n",
    "print('tRNN MSE beta std'  , np.array(mse_beta_trnn).std()  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8917ad7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('QPS BCE %.3f'          %np.array(bce_arr_qs).mean()   )\n",
    "print('QPS MSE alpha %.3f'    %np.array(mse_alpha_qs).mean() )\n",
    "print('QPS MSE beta %.3f'     %np.array(mse_beta_qs).mean()  )\n",
    "\n",
    "print('=============================')\n",
    "\n",
    "print('BAY BCE %.3f'        %np.array(bce_arr_bay).mean()   )\n",
    "print('BAY MSE alpha %.3f'  %np.array(mse_alpha_bay).mean() )\n",
    "print('BAY MSE beta %.3f'   %np.array(mse_beta_bay).mean()  )\n",
    "\n",
    "print('=============================')\n",
    "\n",
    "print('tRNN BCE %.3f'        %np.array(bce_arr_trnn).mean()   )\n",
    "print('tRNN MSE alpha %.3f'  %np.array(mse_alpha_trnn).mean() )\n",
    "print('tRNN MSE beta %.3f'   %np.array(mse_beta_trnn).mean()  )\n",
    "\n",
    "\n",
    "all_res = pd.DataFrame({'Measurements':np.concatenate([\n",
    "                    np.array(bce_arr_qs),np.array(mse_alpha_qs),np.array(mse_beta_qs),\n",
    "                    np.array(bce_arr_bay),np.array(mse_alpha_bay),np.array(mse_beta_bay),\n",
    "                    np.array(bce_arr_trnn),np.array(mse_alpha_trnn),np.array(mse_beta_trnn)]),\n",
    "           \n",
    "              'Model':\n",
    "                    np.repeat(['Q-stationary','Bayesian','t-RNN'],3*num_of_agent),\n",
    "              \n",
    "              'Type':\n",
    "#                     np.tile(np.repeat([r'$BCE\\/\\/\\/$'+'\\n action',r'$MSE_{\\alpha}$',r'$MSE_{\\beta}$'],num_of_agent),3)\n",
    "                      np.tile(np.repeat([r'$BCE_{action}$',r'$MSE_{\\alpha}$',r'$MSE_{\\beta}$'],num_of_agent),3)\n",
    "             })\n",
    "\n",
    "plt.figure(figsize=(5.5,4))\n",
    "sns.barplot(data=all_res,\n",
    "            y='Type',x='Measurements',hue='Model',\n",
    "            palette=['tab:green','#ffc100','#1761B0'],\n",
    "            edgecolor='k',\n",
    "            errorbar=\"se\",\n",
    "            orient='h'\n",
    "           )\n",
    "\n",
    "# plt.grid(alpha=0.5,axis='x')\n",
    "plt.tick_params(axis='both', which='major', labelsize=22)\n",
    "plt.xlabel('Erorr (lower is better)',size=22)\n",
    "plt.ylabel('',size=0)\n",
    "plt.xlim(0,0.5)\n",
    "plt.xticks([0.1,0.4])\n",
    "plt.legend(fontsize=18)\n",
    "sns.despine()\n",
    "plt.savefig('../plots/fig_2A_H.pdf',bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e67ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax1 = plt.subplots(1,1,figsize=(5,5.5))\n",
    "sns.barplot(ax=ax1,data=all_res,\n",
    "            x='Type',y='Measurements',hue='Model',\n",
    "            palette=['tab:green','#ffc100','#1761B0'],\n",
    "            edgecolor='k',\n",
    "            errorbar=\"se\",\n",
    "            orient='v'\n",
    "           )\n",
    "\n",
    "# plt.grid(alpha=0.5,axis='both')\n",
    "ax1.tick_params(axis='both', which='major', labelsize=20)\n",
    "ax1.set_ylabel('Erorr (lower is better)',size=20)\n",
    "ax1.set_xlabel('',size=0)\n",
    "ax1.set_ylim(0,0.4)\n",
    "ax1.set_yticks([0.1,0.3])\n",
    "ax1.legend(fontsize=16)\n",
    "ax1.set_yticklabels([str(x)[1:] for x in np.round(ax1.get_yticks(), 3)])\n",
    "\n",
    "sns.despine()\n",
    "plt.savefig('../plots/fig_2A_V.pdf',bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b657f1d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pla = ['#D2292D','tab:green','#ffc100','#1761B0']\n",
    "\n",
    "for i in [15,22,8]: # range(num_of_agent): \n",
    "    \n",
    "    cur = all_data[i]\n",
    "    \n",
    "    fig, (ax0,ax1) = plt.subplots(1,2,figsize=(10,1.8))\n",
    "        \n",
    "    sns.lineplot(ax=ax0,x=np.arange(num_of_trials),y=np.repeat(alpha_qs[i],num_of_trials),color=pla[1],lw=2,ls=(0, (5, 1))) # qps\n",
    "    sns.lineplot(ax=ax0,x=np.arange(num_of_trials),y=alpha_bay[i],color=pla[2],lw=2,ls=(0, (5, 1)))# bay\n",
    "    sns.lineplot(ax=ax0,x=np.arange(num_of_trials),y=alpha_trnn[i],color=pla[3],lw=2,ls=(0, (5, 1)))\n",
    "    sns.lineplot(ax=ax0,x=np.arange(num_of_trials),y=cur.alpha,color=pla[0],lw=3) # target\n",
    "        \n",
    "\n",
    "    sns.lineplot(ax=ax1,x=np.arange(num_of_trials),y=np.repeat(beta_qs[i],num_of_trials),color=pla[1],lw=2,ls=(0, (5, 1))) # qps\n",
    "    sns.lineplot(ax=ax1,x=np.arange(num_of_trials),y=beta_bay[i],color=pla[2],lw=2,ls=(0, (5, 1))) # bay\n",
    "    sns.lineplot(ax=ax1,x=np.arange(num_of_trials),y=beta_trnn[i],color=pla[3],lw=2,ls=(0, (5, 1)))\n",
    "    sns.lineplot(ax=ax1,x=np.arange(num_of_trials),y=cur.beta,color=pla[0],lw=3)\n",
    "    \n",
    "    ax0.set_xticklabels([])\n",
    "    ax0.set_xlim(0,num_of_trials)\n",
    "    ax0.set_ylim(-0.2,1.2)\n",
    "    ax0.set_ylabel(r'$\\alpha$',size=25,labelpad=0)\n",
    "    ax0.set_yticks([.1,.8])\n",
    "    ax0.set_yticklabels([.1,0.8],size=16)\n",
    "    ax0.set_yticklabels([str(x)[1:] for x in np.round(ax0.get_yticks(), 3)])\n",
    "    \n",
    "    ax1.set_xlim(0,num_of_trials)\n",
    "    ax1.set_ylim(-0.1,10.1)\n",
    "    ax1.set_ylabel(r'$\\beta$',size=25,labelpad=0)\n",
    "    ax1.set_yticks([1,8])\n",
    "    ax1.set_yticklabels([1,8],size=16)\n",
    "    ax1.set_xlabel('Trial',size=16)\n",
    "    \n",
    "    ax0.set_xlim(0,1000)\n",
    "    ax0.set_xticks([100,500,900])\n",
    "    ax0.set_xticklabels([100,500,900],size=16)\n",
    "    ax0.set_xlabel('Trial',size=16)\n",
    "    \n",
    "    ax1.set_xlim(0,1000)\n",
    "    ax1.set_xticks([100,500,900])\n",
    "    ax1.set_xticklabels([100,500,900],size=16)\n",
    "    \n",
    "\n",
    "    legend_elements = [Line2D([0],[0] ,lw=4, color=pla[0], label='Target'),\n",
    "                       Line2D([0],[0] ,lw=4, color=pla[1], label='Q-stationary'),\n",
    "                       Line2D([0],[0] ,lw=4, color=pla[2], label='Bayesian'),\n",
    "                       Line2D([0],[0] ,lw=4, color=pla[3], label='t-RNN'),\n",
    "                      ]\n",
    "\n",
    "    if i == 8:\n",
    "        ax1.legend(handles=legend_elements,bbox_to_anchor=(1.05, 1),ncol=1,loc='upper left', borderaxespad=0.,\n",
    "                  fontsize=14)\n",
    "\n",
    "    sns.despine()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'../plots/fig_2B_{i}.pdf')\n",
    "    plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ea4cd1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pla = ['#D2292D','tab:green','#ffc100','#1761B0']\n",
    "\n",
    "for i in range(num_of_agent): \n",
    "    \n",
    "    cur = all_data[i]\n",
    "    \n",
    "    fig, (ax0,ax1) = plt.subplots(1,2,figsize=(10,1.8))\n",
    "        \n",
    "    sns.lineplot(ax=ax0,x=np.arange(num_of_trials),y=np.repeat(alpha_qs[i],num_of_trials),color=pla[1],lw=2,ls=(0, (5, 1))) # qps\n",
    "    sns.lineplot(ax=ax0,x=np.arange(num_of_trials),y=alpha_bay[i],color=pla[2],lw=2,ls=(0, (5, 1)))# bay\n",
    "    sns.lineplot(ax=ax0,x=np.arange(num_of_trials),y=alpha_trnn[i],color=pla[3],lw=2,ls=(0, (5, 1)))\n",
    "    sns.lineplot(ax=ax0,x=np.arange(num_of_trials),y=cur.alpha,color=pla[0],lw=3) # target\n",
    "        \n",
    "\n",
    "    sns.lineplot(ax=ax1,x=np.arange(num_of_trials),y=np.repeat(beta_qs[i],num_of_trials),color=pla[1],lw=2,ls=(0, (5, 1))) # qps\n",
    "    sns.lineplot(ax=ax1,x=np.arange(num_of_trials),y=beta_bay[i],color=pla[2],lw=2,ls=(0, (5, 1))) # bay\n",
    "    sns.lineplot(ax=ax1,x=np.arange(num_of_trials),y=beta_trnn[i],color=pla[3],lw=2,ls=(0, (5, 1)))\n",
    "    sns.lineplot(ax=ax1,x=np.arange(num_of_trials),y=cur.beta,color=pla[0],lw=3)\n",
    "    \n",
    "    ax0.set_xticklabels([])\n",
    "    ax0.set_xlim(0,num_of_trials)\n",
    "    ax0.set_ylim(-0.2,1.2)\n",
    "    ax0.set_ylabel(r'$\\alpha$',size=25,labelpad=0)\n",
    "    ax0.set_yticks([.1,.8])\n",
    "    ax0.set_yticklabels([.1,0.8],size=16)\n",
    "    ax0.set_yticklabels([str(x)[1:] for x in np.round(ax0.get_yticks(), 3)])\n",
    "    \n",
    "    ax1.set_xlim(0,num_of_trials)\n",
    "    ax1.set_ylim(-0.1,10.1)\n",
    "    ax1.set_ylabel(r'$\\beta$',size=25,labelpad=0)\n",
    "    ax1.set_yticks([1,8])\n",
    "    ax1.set_yticklabels([1,8],size=16)\n",
    "    ax1.set_xlabel('Trial',size=16)\n",
    "    \n",
    "    ax0.set_xlim(0,1000)\n",
    "    ax0.set_xticks([100,500,900])\n",
    "    ax0.set_xticklabels([100,500,900],size=16)\n",
    "    ax0.set_xlabel('Trial',size=16)\n",
    "    \n",
    "    ax1.set_xlim(0,1000)\n",
    "    ax1.set_xticks([100,500,900])\n",
    "    ax1.set_xticklabels([100,500,900],size=16)\n",
    "    \n",
    "\n",
    "    sns.despine()\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.show()\n",
    "        \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
