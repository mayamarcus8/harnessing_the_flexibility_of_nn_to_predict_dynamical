{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67e92ac7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "import time\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d88b2d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRU_RNN_TWO(nn.Module):\n",
    "        \n",
    "    def __init__(self,input_size, hidden_size, num_of_layers, num_alpha_embedding, num_beta_embedding, dropout):\n",
    "        \n",
    "        super(GRU_RNN_TWO, self).__init__()\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.num_alpha_embedding = num_alpha_embedding\n",
    "        self.num_beta_embedding = num_beta_embedding        \n",
    "        \n",
    "        self.hidden_0 = nn.GRU(  \n",
    "                    input_size=input_size,\n",
    "                    hidden_size=hidden_size,\n",
    "                    num_layers=num_of_layers,\n",
    "                    batch_first=True,\n",
    "                    dropout=dropout\n",
    "        )\n",
    "    \n",
    "\n",
    "        self.out_alpha = nn.Linear(hidden_size, num_alpha_embedding)\n",
    "        self.out_beta = nn.Linear(hidden_size, num_beta_embedding)\n",
    "        \n",
    "        self.relu_alpha = nn.ReLU()\n",
    "        self.relu_beta = nn.ReLU()\n",
    "\n",
    "        self.reg_alpha = nn.Linear(num_alpha_embedding, 1)\n",
    "        self.reg_beta = nn.Linear(num_beta_embedding, 1)\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "\n",
    "        # parameters estimation\n",
    "        output_0, hn_0 = self.hidden_0(x)\n",
    "        \n",
    "        output_alpha = self.out_alpha(output_0)\n",
    "        output_alpha = self.relu_alpha(output_alpha)\n",
    "        \n",
    "        output_beta = self.out_beta(output_0)\n",
    "        output_beta = self.relu_beta(output_beta)\n",
    "        \n",
    "        cont_output_alpha = self.reg_alpha(output_alpha)\n",
    "        cont_output_beta = self.reg_beta(output_beta)\n",
    "        \n",
    "        output_dis = [output_alpha, output_beta]\n",
    "        output_cont = [cont_output_alpha, cont_output_beta]\n",
    "\n",
    "        return output_dis, output_cont, hn_0\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ccca69bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class behavior_dataset(Dataset):\n",
    "    \"\"\"         \n",
    "    \"\"\"\n",
    "    def __init__(self,dataframe):\n",
    "        \n",
    "        # action one hot transformation \n",
    "        action = np.array(dataframe['action'])\n",
    "        if np.all(action == action[0]):\n",
    "            action = np.append(action,(1-action[0]))\n",
    "            action = torch.tensor((action).reshape(len(dataframe) + 1),dtype=int)\n",
    "            action_onehot = nn.functional.one_hot(action, len(action.unique()))\n",
    "            # delete last one\n",
    "            action_onehot = action_onehot[:-1]\n",
    "        else:\n",
    "            action = torch.tensor((action).reshape(len(dataframe)),dtype=int)\n",
    "            action_onehot = nn.functional.one_hot(action, len(action.unique()))\n",
    "        \n",
    "        # reward\n",
    "        reward = torch.tensor((np.array(dataframe['reward'])).reshape(len(dataframe)),dtype=int)\n",
    "        \n",
    "        # concatinating reward and action\n",
    "        reward_action = torch.cat([reward[ :, np.newaxis], action_onehot],1)\n",
    "        \n",
    "        # adding dummy zeros to the beginning and ignoring the last one\n",
    "        reward_action_shift = nn.functional.pad(reward_action,[0,0,1,0])[:-1]\n",
    "        \n",
    "        # parameters one hot transformation \n",
    "        dis_alpha = torch.tensor((np.array(dataframe['alpha_bin'])).reshape(len(dataframe)),dtype=int)\n",
    "        dis_alpha = dis_alpha.type(dtype=torch.float32)\n",
    "        \n",
    "        # parameters one hot transformation \n",
    "        dis_beta = torch.tensor((np.array(dataframe['beta_bin'])).reshape(len(dataframe)),dtype=int)\n",
    "        dis_beta = dis_beta.type(dtype=torch.float32)\n",
    "\n",
    "        cont_alpha = torch.tensor((np.array(dataframe['alpha'])).reshape(len(dataframe)),dtype=torch.float32)\n",
    "        cont_beta = torch.tensor((np.array(dataframe['beta'])).reshape(len(dataframe)),dtype=torch.float32)\n",
    "        \n",
    "        # network input \n",
    "        x = reward_action_shift\n",
    "        \n",
    "        n_blocks = int(len(dataframe)/100)\n",
    "        x.reshape(n_blocks,100,3)[:,0,:] = torch.zeros(size=(n_blocks,3))\n",
    "        \n",
    "        # network output \n",
    "        y = torch.cat([action_onehot, dis_alpha[ :, np.newaxis],  dis_beta[ :, np.newaxis], \n",
    "                                      cont_alpha[ :, np.newaxis], cont_beta[ :, np.newaxis]\n",
    "                      ],1)\n",
    "  \n",
    "        self.x = x.type(dtype=torch.float32)\n",
    "        self.y = y.type(dtype=torch.float32)\n",
    "        self.len = len(dataframe)\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        return self.x[idx],self.y[idx]\n",
    "  \n",
    "    def __len__(self):\n",
    "        return self.len    \n",
    "    \n",
    "class merge_behavior_dataset(Dataset):\n",
    "    \"\"\" \n",
    "    Merge Dataset of each agent to one dataset\n",
    "    \n",
    "    Args:\n",
    "        dataset_list: list of Dataset of all agent \n",
    "        n_trials: num_of_trials each agent was simulated\n",
    "        \n",
    "    Returns: \n",
    "        torch Dataset:\n",
    "        x: [reward_(t-1) , action_(t-1)] all agents\n",
    "        y: [action_t, parameter embedding] all agents\n",
    "        \n",
    "    \"\"\"\n",
    "    def __init__(self, dataset_list, n_trials):\n",
    "        X = []\n",
    "        Y = []\n",
    "        for agent in dataset_list:\n",
    "            for i in range(n_trials):\n",
    "                X.append(agent[i][0])\n",
    "                Y.append(agent[i][1])\n",
    "                \n",
    "        self.x = torch.stack(X).type(dtype=torch.float32)\n",
    "        self.y = torch.stack(Y).type(dtype=torch.float32)\n",
    "        self.len = len(X)   \n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        return self.x[idx],self.y[idx]\n",
    "  \n",
    "    def __len__(self):\n",
    "        return self.len    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ebbb110",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_two(net, train_loader, val_loader ,epochs, name):\n",
    "        \n",
    "    min_loss_t = 100\n",
    "    min_loss_v = 100\n",
    "        \n",
    "    # array to track loss \n",
    "    train_loss_array , val_loss_array = [], []\n",
    "    \n",
    "    # move net to GPU\n",
    "    net.to(device)\n",
    "\n",
    "    # Use Adam optimizer\n",
    "    optimizer = optim.Adam(net.parameters(), lr=0.001) \n",
    "    \n",
    "    # start timer\n",
    "    start_time = time.time()   \n",
    "    \n",
    "    # Loop over epochs \n",
    "    for i in range(epochs):        \n",
    "        # Randomize train batch example \n",
    "        train_loader = random.sample(list(train_loader), len(train_loader))\n",
    "      \n",
    "        running_loss = 0\n",
    "        \n",
    "        run_d_alpha ,run_d_beta = 0,0\n",
    "        run_c_alpha, run_c_beta  = 0,0 \n",
    "        # Loop over training batches\n",
    "        for j, (X, y_true) in enumerate(train_loader):\n",
    "    \n",
    "            X, y_true = X.to(device), y_true.to(device) # move to GPU\n",
    "            X = X.reshape(1,X.shape[0],INPUT_SIZE) # reshape to  1 x trials x input_size\n",
    "            \n",
    "            optimizer.zero_grad()  # zero the gradient buffers\n",
    "            \n",
    "            y_hat_dis, y_hat_cont, _  = net(X) # forward pass\n",
    "            \n",
    "            y_hat_dis_alpha = (y_hat_dis[0].view(-1, num_alpha_embedding)) # Reshape to (SeqLen x Batch, OutputSize)\n",
    "            y_hat_dis_beta = (y_hat_dis[1].view(-1, num_beta_embedding)) # Reshape to (SeqLen x Batch, OutputSize)\n",
    "\n",
    "            \n",
    "            y_hat_dis = [y_hat_dis_alpha,y_hat_dis_beta]\n",
    " \n",
    "            y_hat_cont_alpha = (y_hat_cont[0].view(-1)) # Reshape to (SeqLen x Batch, OutputSize)\n",
    "            y_hat_cont_beta = (y_hat_cont[1].view(-1)) # Reshape to (SeqLen x Batch, OutputSize)\n",
    "\n",
    "            \n",
    "            y_hat_cont = [y_hat_cont_alpha,y_hat_cont_beta]\n",
    "\n",
    "            loss, l_dis, l_cont = multi_loss(y_hat_dis, y_hat_cont, y_true) # compute loss\n",
    "                                                                                           \n",
    "\n",
    "            loss.backward() # backprop the loss\n",
    "            optimizer.step() # update the weights \n",
    "            running_loss += loss.item()\n",
    "        \n",
    "            run_d_alpha += l_dis[0].item()\n",
    "            run_d_beta += l_dis[1].item()\n",
    "            \n",
    "            run_c_alpha += l_cont[0].item()\n",
    "            run_c_beta += l_cont[1].item()\n",
    "\n",
    "            \n",
    "        train_loss_array.append(running_loss/len(train_loader))\n",
    "        loss = eval_net_two(net,val_loader)\n",
    "        val_loss_array.append(loss)\n",
    "        \n",
    "\n",
    "        \n",
    "        print('================')\n",
    "        print('loss CE alpha',(run_d_alpha/len(train_loader)))\n",
    "        print('loss CE beta',(run_d_beta/len(train_loader)))\n",
    "\n",
    "        \n",
    "        print('================')\n",
    "        print('loss mse alpha',(run_c_alpha/len(train_loader)))\n",
    "        print('loss mse beta',(run_c_beta/len(train_loader)))\n",
    "    \n",
    "        \n",
    "        if train_loss_array[i] <= min_loss_t:\n",
    "            checkpoint = {'epoch':i+1,'model_state':net.state_dict(),\n",
    "                          'optim_state':optimizer.state_dict(),'loss':train_loss_array[i]}\n",
    "            torch.save(checkpoint,f'checkpoint/checkpoint_trnn_train{name}.pth')\n",
    "\n",
    "            min_loss_t = train_loss_array[i]\n",
    "\n",
    "        if val_loss_array[i] <= min_loss_v:\n",
    "            checkpoint = {'epoch':i+1,'model_state':net.state_dict(),\n",
    "                          'optim_state':optimizer.state_dict(),'loss':val_loss_array[i]}\n",
    "            torch.save(checkpoint,f'checkpoint/checkpoint_trnn_val{name}.pth')\n",
    "\n",
    "            min_loss_v = val_loss_array[i]\n",
    "\n",
    "        print('Step {}, Train Loss {:0.4f}, Val Loss {:0.4f}, Time {:0.1f}s'.format(i+1,\n",
    "                                                                                    train_loss_array[i],\n",
    "                                                                                    val_loss_array[i],\n",
    "                                                                                    time.time() - start_time))\n",
    "\n",
    "        net.train()\n",
    "\n",
    "            \n",
    "    return net, train_loss_array , val_loss_array "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf1b9c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_net_two(net, val_loader):\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        net.eval()\n",
    "        running_loss = 0\n",
    "        for j, (X, y_true) in enumerate(val_loader):\n",
    "            \n",
    "            X, y_true = X.to(device), y_true.to(device) # move to GPU\n",
    "            X = X.reshape(1,X.shape[0],INPUT_SIZE) # reshape to  1 x trials x input_size\n",
    "            \n",
    "            y_hat_dis, y_hat_cont, _  = net(X) # forward pass\n",
    "            \n",
    "            y_hat_dis_alpha = (y_hat_dis[0].view(-1, num_alpha_embedding)) # Reshape to (SeqLen x Batch, OutputSize)\n",
    "            y_hat_dis_beta = (y_hat_dis[1].view(-1, num_beta_embedding)) # Reshape to (SeqLen x Batch, OutputSize)\n",
    "\n",
    "            \n",
    "            y_hat_dis = [y_hat_dis_alpha,y_hat_dis_beta]\n",
    " \n",
    "            y_hat_cont_alpha = (y_hat_cont[0].view(-1)) # Reshape to (SeqLen x Batch, OutputSize)\n",
    "            y_hat_cont_beta = (y_hat_cont[1].view(-1)) # Reshape to (SeqLen x Batch, OutputSize)\n",
    "\n",
    "            \n",
    "            y_hat_cont = [y_hat_cont_alpha,y_hat_cont_beta]\n",
    "\n",
    "            loss, l_dis, l_cont = multi_loss(y_hat_dis, y_hat_cont, y_true) # compute loss\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "    \n",
    "    return (running_loss/len(val_loader))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc7121a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_of_trials: 1000\n",
      "num_of_agents: 100\n",
      "num_alpha_embedding: 5\n",
      "num_beta_embedding: 5\n",
      "train_size: 80000\n",
      "train_size: torch.Size([80000, 3])\n",
      "val_size: 20000\n",
      "val_size: torch.Size([20000, 3])\n"
     ]
    }
   ],
   "source": [
    "path = f'../data/artificial_trainset_2000_alphastat_03.csv' # Maya - changed path\n",
    "df = pd.read_csv(path)\n",
    "\n",
    "# define constant \n",
    "num_of_action = df['action'].nunique()\n",
    "num_of_trials = df['trial'].nunique()\n",
    "num_of_agents = df['agent'].nunique()\n",
    "num_alpha_embedding = 5 # df['alpha_bin'].nunique()\n",
    "num_beta_embedding = df['beta_bin'].nunique()\n",
    "\n",
    "# netowrk input and output dimension  \n",
    "INPUT_SIZE = 1 + num_of_action\n",
    "\n",
    "\n",
    "# train val test split \n",
    "n_agent_train = int(0.8*num_of_agents)\n",
    "n_agent_val = int(0.2*num_of_agents)\n",
    "\n",
    "all_data = []\n",
    "for i in range(num_of_agents):\n",
    "    s = i*num_of_trials\n",
    "    e = (i+1)*num_of_trials\n",
    "    cur_df = df.iloc[s:e]\n",
    "    cur_df = cur_df.reset_index()\n",
    "    all_data.append([i,behavior_dataset(cur_df)])\n",
    "    \n",
    "random.shuffle(all_data)\n",
    "all_data = np.array(all_data, dtype=object)\n",
    "train_dataset = all_data[:n_agent_train,1]\n",
    "train_dataset = merge_behavior_dataset(train_dataset,num_of_trials)\n",
    "\n",
    "val_dataset = all_data[n_agent_train:,1]\n",
    "val_dataset = merge_behavior_dataset(val_dataset,num_of_trials)\n",
    "val_agents = np.array([all_data[i,0] for i in range(n_agent_train,num_of_agents)])\n",
    "    \n",
    "print('num_of_trials:',num_of_trials)\n",
    "print('num_of_agents:',num_of_agents)\n",
    "print('num_alpha_embedding:',num_alpha_embedding)\n",
    "print('num_beta_embedding:',num_beta_embedding)\n",
    "print('train_size:', n_agent_train*num_of_trials)\n",
    "print('train_size:', train_dataset[:][0].shape)\n",
    "print('val_size:', n_agent_val*num_of_trials)\n",
    "print('val_size:', val_dataset[:][0].shape)\n",
    "# print('val_agents',val_agents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3041c824",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_loss(y_hat_dis, y_hat_cont, y_true):\n",
    "    \n",
    "    # slice true parameters embedding \n",
    "    y_true_dis_alpha = torch.flatten(y_true[:,2])\n",
    "    y_true_dis_alpha = y_true_dis_alpha.type(dtype=torch.LongTensor).to(device)\n",
    "    \n",
    "    y_true_dis_beta = torch.flatten(y_true[:,3])\n",
    "    y_true_dis_beta = y_true_dis_beta.type(dtype=torch.LongTensor).to(device)\n",
    "    \n",
    "    y_true_cont_alpha =  y_true[:,4]\n",
    "    y_true_cont_beta =  y_true[:,5]\n",
    "    \n",
    "    # define losses\n",
    "    criterion1 = nn.CrossEntropyLoss()\n",
    "    criterion2 = nn.MSELoss()\n",
    "    \n",
    "    l_dis_alpha = criterion1(y_hat_dis[0], y_true_dis_alpha)\n",
    "    l_dis_beta = criterion1(y_hat_dis[1], y_true_dis_beta)\n",
    "    \n",
    "    l_cont_alpha = criterion2(y_hat_cont[0],y_true_cont_alpha)\n",
    "    l_cont_beta = criterion2(y_hat_cont[1],y_true_cont_beta)\n",
    "    \n",
    "    # combine losses\n",
    "    total_loss = 0.2*l_dis_alpha  +  0.2*l_dis_beta  + 6*l_cont_alpha  + 0.1*l_cont_beta \n",
    "                \n",
    "    return total_loss, [0.2*l_dis_alpha,  0.2*l_dis_beta ], [6*l_cont_alpha, 0.1*l_cont_beta] \n",
    "                                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "43bab64a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "loss CE alpha 0.23358981683850288\n",
      "loss CE beta 0.3404260043054819\n",
      "================\n",
      "loss mse alpha 0.8651332062203437\n",
      "loss mse beta 2.700174264644738\n",
      "Step 1, Train Loss 4.1393, Val Loss 2.2747, Time 2.8s\n",
      "================\n",
      "loss CE alpha 0.1202891480177641\n",
      "loss CE beta 0.46569044440984725\n",
      "================\n",
      "loss mse alpha 0.012528051144909114\n",
      "loss mse beta 1.2432750589214265\n",
      "Step 2, Train Loss 1.8418, Val Loss 1.3444, Time 4.2s\n",
      "================\n",
      "loss CE alpha 0.08850733749568462\n",
      "loss CE beta 0.4373720809817314\n",
      "================\n",
      "loss mse alpha 0.007333886052947491\n",
      "loss mse beta 0.9371952493442223\n",
      "Step 3, Train Loss 1.4704, Val Loss 1.2686, Time 5.7s\n",
      "================\n",
      "loss CE alpha 0.07186563136056065\n",
      "loss CE beta 0.3956962700933218\n",
      "================\n",
      "loss mse alpha 0.00651200955035165\n",
      "loss mse beta 0.9421826816862449\n",
      "Step 4, Train Loss 1.4163, Val Loss 1.2376, Time 7.1s\n",
      "================\n",
      "loss CE alpha 0.05355476648546755\n",
      "loss CE beta 0.38693145513534544\n",
      "================\n",
      "loss mse alpha 0.005727427633246407\n",
      "loss mse beta 0.9341458299895748\n",
      "Step 5, Train Loss 1.3804, Val Loss 1.2257, Time 8.4s\n",
      "================\n",
      "loss CE alpha 0.03671818536240608\n",
      "loss CE beta 0.3888614926487207\n",
      "================\n",
      "loss mse alpha 0.004961347905918956\n",
      "loss mse beta 0.9253210477530956\n",
      "Step 6, Train Loss 1.3559, Val Loss 1.1989, Time 9.8s\n",
      "================\n",
      "loss CE alpha 0.024689615610986947\n",
      "loss CE beta 0.3853249019011855\n",
      "================\n",
      "loss mse alpha 0.004788454656954854\n",
      "loss mse beta 0.9314682635013014\n",
      "Step 7, Train Loss 1.3463, Val Loss 1.1857, Time 11.2s\n",
      "================\n",
      "loss CE alpha 0.016995534487068652\n",
      "loss CE beta 0.38218434266746043\n",
      "================\n",
      "loss mse alpha 0.0045410365564748645\n",
      "loss mse beta 0.9298966925824061\n",
      "Step 8, Train Loss 1.3336, Val Loss 1.1805, Time 12.6s\n",
      "================\n",
      "loss CE alpha 0.011587033967953176\n",
      "loss CE beta 0.38943278361111877\n",
      "================\n",
      "loss mse alpha 0.004276895645307377\n",
      "loss mse beta 0.9220637153834105\n",
      "Step 9, Train Loss 1.3274, Val Loss 1.1730, Time 13.9s\n",
      "================\n",
      "loss CE alpha 0.009458631742745638\n",
      "loss CE beta 0.38016984835267065\n",
      "================\n",
      "loss mse alpha 0.004246798876556568\n",
      "loss mse beta 0.9333788779331371\n",
      "Step 10, Train Loss 1.3273, Val Loss 1.1647, Time 15.4s\n",
      "================\n",
      "loss CE alpha 0.007187508582137525\n",
      "loss CE beta 0.380931593477726\n",
      "================\n",
      "loss mse alpha 0.0040263877104735005\n",
      "loss mse beta 0.9250789889367297\n",
      "Step 11, Train Loss 1.3172, Val Loss 1.1631, Time 17.0s\n",
      "================\n",
      "loss CE alpha 0.005820334720192477\n",
      "loss CE beta 0.38170289490371945\n",
      "================\n",
      "loss mse alpha 0.00389754893258214\n",
      "loss mse beta 0.9144330004928634\n",
      "Step 12, Train Loss 1.3059, Val Loss 1.1485, Time 18.6s\n",
      "================\n",
      "loss CE alpha 0.0053221701760776344\n",
      "loss CE beta 0.3757807457819581\n",
      "================\n",
      "loss mse alpha 0.004028953195665963\n",
      "loss mse beta 0.9058392612962052\n",
      "Step 13, Train Loss 1.2910, Val Loss 1.1612, Time 20.2s\n",
      "================\n",
      "loss CE alpha 0.004407568590249866\n",
      "loss CE beta 0.3795241449028254\n",
      "================\n",
      "loss mse alpha 0.003702293988317251\n",
      "loss mse beta 0.8994648721534759\n",
      "Step 14, Train Loss 1.2871, Val Loss 1.1225, Time 21.8s\n",
      "================\n",
      "loss CE alpha 0.004408715423778631\n",
      "loss CE beta 0.37589380145072937\n",
      "================\n",
      "loss mse alpha 0.003966090007452294\n",
      "loss mse beta 0.8733267799252644\n",
      "Step 15, Train Loss 1.2576, Val Loss 1.0946, Time 23.4s\n",
      "================\n",
      "loss CE alpha 0.00454186444694642\n",
      "loss CE beta 0.37292485442012546\n",
      "================\n",
      "loss mse alpha 0.005071356895496137\n",
      "loss mse beta 0.839470283780247\n",
      "Step 16, Train Loss 1.2220, Val Loss 1.1034, Time 24.8s\n",
      "================\n",
      "loss CE alpha 0.004392697877483443\n",
      "loss CE beta 0.37240493632853033\n",
      "================\n",
      "loss mse alpha 0.006495214253664017\n",
      "loss mse beta 0.81474026911892\n",
      "Step 17, Train Loss 1.1980, Val Loss 1.0343, Time 26.2s\n",
      "================\n",
      "loss CE alpha 0.0055212925130035725\n",
      "loss CE beta 0.37596983518451454\n",
      "================\n",
      "loss mse alpha 0.01390923393482808\n",
      "loss mse beta 0.7298210789449513\n",
      "Step 18, Train Loss 1.1252, Val Loss 1.0540, Time 27.6s\n",
      "================\n",
      "loss CE alpha 0.006360293482430279\n",
      "loss CE beta 0.37174637205898764\n",
      "================\n",
      "loss mse alpha 0.010526096797548234\n",
      "loss mse beta 0.6915406292770058\n",
      "Step 19, Train Loss 1.0802, Val Loss 0.9397, Time 29.0s\n",
      "================\n",
      "loss CE alpha 0.008861515129683539\n",
      "loss CE beta 0.3692303910851479\n",
      "================\n",
      "loss mse alpha 0.012699010164942593\n",
      "loss mse beta 0.6004035760648548\n",
      "Step 20, Train Loss 0.9912, Val Loss 0.9118, Time 30.4s\n",
      "================\n",
      "loss CE alpha 0.010261806848575361\n",
      "loss CE beta 0.3661336192861199\n",
      "================\n",
      "loss mse alpha 0.011122989503201097\n",
      "loss mse beta 0.5406638888642192\n",
      "Step 21, Train Loss 0.9282, Val Loss 0.8666, Time 31.8s\n",
      "================\n",
      "loss CE alpha 0.008773480322270188\n",
      "loss CE beta 0.36096626315265895\n",
      "================\n",
      "loss mse alpha 0.005619091540575027\n",
      "loss mse beta 0.5024556248448789\n",
      "Step 22, Train Loss 0.8778, Val Loss 0.8514, Time 33.2s\n",
      "================\n",
      "loss CE alpha 0.0091335586970672\n",
      "loss CE beta 0.35825097691267727\n",
      "================\n",
      "loss mse alpha 0.006020867818733677\n",
      "loss mse beta 0.4582832930609584\n",
      "Step 23, Train Loss 0.8317, Val Loss 0.8685, Time 34.6s\n",
      "================\n",
      "loss CE alpha 0.0073062831637798805\n",
      "loss CE beta 0.35620999094098804\n",
      "================\n",
      "loss mse alpha 0.004493218133575283\n",
      "loss mse beta 0.44393118657171726\n",
      "Step 24, Train Loss 0.8119, Val Loss 0.8145, Time 36.0s\n",
      "================\n",
      "loss CE alpha 0.006928161000541877\n",
      "loss CE beta 0.3512594414874911\n",
      "================\n",
      "loss mse alpha 0.0035509207838913424\n",
      "loss mse beta 0.4213307616300881\n",
      "Step 25, Train Loss 0.7831, Val Loss 0.7864, Time 37.5s\n",
      "================\n",
      "loss CE alpha 0.00600004106090637\n",
      "loss CE beta 0.3483381289988756\n",
      "================\n",
      "loss mse alpha 0.0034594167285831646\n",
      "loss mse beta 0.41369229294359683\n",
      "Step 26, Train Loss 0.7715, Val Loss 0.7910, Time 38.9s\n",
      "================\n",
      "loss CE alpha 0.005474596145359101\n",
      "loss CE beta 0.34403844121843574\n",
      "================\n",
      "loss mse alpha 0.0030299281759653242\n",
      "loss mse beta 0.39384327731095253\n",
      "Step 27, Train Loss 0.7464, Val Loss 0.8230, Time 40.5s\n",
      "================\n",
      "loss CE alpha 0.004884626845159801\n",
      "loss CE beta 0.3414804980158806\n",
      "================\n",
      "loss mse alpha 0.0032963092060526835\n",
      "loss mse beta 0.3926726192701608\n",
      "Step 28, Train Loss 0.7423, Val Loss 0.7825, Time 42.1s\n",
      "================\n",
      "loss CE alpha 0.0041883050434989855\n",
      "loss CE beta 0.3386987656354904\n",
      "================\n",
      "loss mse alpha 0.002632518613245338\n",
      "loss mse beta 0.37129962919279935\n",
      "Step 29, Train Loss 0.7168, Val Loss 0.7160, Time 43.7s\n",
      "================\n",
      "loss CE alpha 0.0035601599040091967\n",
      "loss CE beta 0.31466906405985356\n",
      "================\n",
      "loss mse alpha 0.002843266865238547\n",
      "loss mse beta 0.37212667539715766\n",
      "Step 30, Train Loss 0.6932, Val Loss 0.6535, Time 45.3s\n",
      "================\n",
      "loss CE alpha 0.0036585988709703088\n",
      "loss CE beta 0.2942364474758506\n",
      "================\n",
      "loss mse alpha 0.0029787788138492034\n",
      "loss mse beta 0.3517659704899415\n",
      "Step 31, Train Loss 0.6526, Val Loss 0.6248, Time 46.8s\n",
      "================\n",
      "loss CE alpha 0.003279505765385693\n",
      "loss CE beta 0.27999791167676447\n",
      "================\n",
      "loss mse alpha 0.0026881181926000862\n",
      "loss mse beta 0.35028694504871966\n",
      "Step 32, Train Loss 0.6363, Val Loss 0.6233, Time 48.3s\n",
      "================\n",
      "loss CE alpha 0.003550712996366201\n",
      "loss CE beta 0.2739367539063096\n",
      "================\n",
      "loss mse alpha 0.002674988322542049\n",
      "loss mse beta 0.33930075634270906\n",
      "Step 33, Train Loss 0.6195, Val Loss 0.6043, Time 50.0s\n",
      "================\n",
      "loss CE alpha 0.0033357982807501684\n",
      "loss CE beta 0.2694182565435767\n",
      "================\n",
      "loss mse alpha 0.002428728036466055\n",
      "loss mse beta 0.328409964684397\n",
      "Step 34, Train Loss 0.6036, Val Loss 0.6022, Time 51.6s\n",
      "================\n",
      "loss CE alpha 0.0030620122066466137\n",
      "loss CE beta 0.26358100306242704\n",
      "================\n",
      "loss mse alpha 0.0023669207643251867\n",
      "loss mse beta 0.3200450644362718\n",
      "Step 35, Train Loss 0.5891, Val Loss 0.6015, Time 53.4s\n",
      "================\n",
      "loss CE alpha 0.002798780219745822\n",
      "loss CE beta 0.2602789064869285\n",
      "================\n",
      "loss mse alpha 0.002316249917203095\n",
      "loss mse beta 0.3132242783438414\n",
      "Step 36, Train Loss 0.5786, Val Loss 0.5822, Time 54.8s\n",
      "================\n",
      "loss CE alpha 0.0031598198827850867\n",
      "loss CE beta 0.2578288385644555\n",
      "================\n",
      "loss mse alpha 0.002281975526420865\n",
      "loss mse beta 0.30728831789456307\n",
      "Step 37, Train Loss 0.5706, Val Loss 0.5720, Time 56.2s\n",
      "================\n",
      "loss CE alpha 0.0027590145924477837\n",
      "loss CE beta 0.2551880327984691\n",
      "================\n",
      "loss mse alpha 0.002177912789920811\n",
      "loss mse beta 0.3070449104066938\n",
      "Step 38, Train Loss 0.5672, Val Loss 0.5744, Time 57.6s\n",
      "================\n",
      "loss CE alpha 0.002640146004705457\n",
      "loss CE beta 0.2532594004645944\n",
      "================\n",
      "loss mse alpha 0.0020952545455656946\n",
      "loss mse beta 0.29701809291727843\n",
      "Step 39, Train Loss 0.5550, Val Loss 0.5965, Time 59.0s\n",
      "================\n",
      "loss CE alpha 0.0023265172752871877\n",
      "loss CE beta 0.24966141898185015\n",
      "================\n",
      "loss mse alpha 0.0020601686584996058\n",
      "loss mse beta 0.2940645547583699\n",
      "Step 40, Train Loss 0.5481, Val Loss 0.5878, Time 60.3s\n",
      "================\n",
      "loss CE alpha 0.0020722773755551317\n",
      "loss CE beta 0.24932151492685078\n",
      "================\n",
      "loss mse alpha 0.0020581876407959497\n",
      "loss mse beta 0.29154964494518937\n",
      "Step 41, Train Loss 0.5450, Val Loss 0.5747, Time 61.7s\n",
      "================\n",
      "loss CE alpha 0.0020965773896023166\n",
      "loss CE beta 0.2481144607067108\n",
      "================\n",
      "loss mse alpha 0.0018371194164501503\n",
      "loss mse beta 0.2897293781861663\n",
      "Step 42, Train Loss 0.5418, Val Loss 0.5774, Time 63.2s\n",
      "================\n",
      "loss CE alpha 0.001885301618676749\n",
      "loss CE beta 0.24498222768306732\n",
      "================\n",
      "loss mse alpha 0.001917721015342977\n",
      "loss mse beta 0.2884399506263435\n",
      "Step 43, Train Loss 0.5372, Val Loss 0.5823, Time 64.6s\n",
      "================\n",
      "loss CE alpha 0.0019635789896710774\n",
      "loss CE beta 0.2439788466319442\n",
      "================\n",
      "loss mse alpha 0.0018345953940297477\n",
      "loss mse beta 0.28103713328018787\n",
      "Step 44, Train Loss 0.5288, Val Loss 0.5634, Time 66.1s\n",
      "================\n",
      "loss CE alpha 0.0017192237202834804\n",
      "loss CE beta 0.24246513489633797\n",
      "================\n",
      "loss mse alpha 0.001678154626279138\n",
      "loss mse beta 0.27956994087435305\n",
      "Step 45, Train Loss 0.5254, Val Loss 0.5683, Time 67.5s\n",
      "================\n",
      "loss CE alpha 0.0016424577341240365\n",
      "loss CE beta 0.241185811907053\n",
      "================\n",
      "loss mse alpha 0.001637471464346163\n",
      "loss mse beta 0.2841777441557497\n",
      "Step 46, Train Loss 0.5286, Val Loss 0.5670, Time 68.9s\n",
      "================\n",
      "loss CE alpha 0.001611960949958302\n",
      "loss CE beta 0.24001136291772127\n",
      "================\n",
      "loss mse alpha 0.0017380631557898595\n",
      "loss mse beta 0.2746713970787823\n",
      "Step 47, Train Loss 0.5180, Val Loss 0.6050, Time 70.4s\n",
      "================\n",
      "loss CE alpha 0.0016550285978155443\n",
      "loss CE beta 0.23915709126740695\n",
      "================\n",
      "loss mse alpha 0.002185714853112586\n",
      "loss mse beta 0.27683372707106174\n",
      "Step 48, Train Loss 0.5198, Val Loss 0.5831, Time 71.9s\n",
      "================\n",
      "loss CE alpha 0.0014425368412048557\n",
      "loss CE beta 0.2367005182430148\n",
      "================\n",
      "loss mse alpha 0.0015068956941831856\n",
      "loss mse beta 0.27456608805805444\n",
      "Step 49, Train Loss 0.5142, Val Loss 0.5437, Time 73.5s\n",
      "================\n",
      "loss CE alpha 0.001309258973924443\n",
      "loss CE beta 0.23546360451728104\n",
      "================\n",
      "loss mse alpha 0.001436699347686954\n",
      "loss mse beta 0.2674945490434766\n",
      "Step 50, Train Loss 0.5057, Val Loss 0.5519, Time 75.1s\n",
      "================\n",
      "loss CE alpha 0.001262471948939492\n",
      "loss CE beta 0.2343887658789754\n",
      "================\n",
      "loss mse alpha 0.0013947387400548906\n",
      "loss mse beta 0.26642978242598475\n",
      "Step 51, Train Loss 0.5035, Val Loss 0.5611, Time 76.6s\n",
      "================\n",
      "loss CE alpha 0.0011990184095338919\n",
      "loss CE beta 0.2332998901605606\n",
      "================\n",
      "loss mse alpha 0.0013581619859905913\n",
      "loss mse beta 0.2594917105510831\n",
      "Step 52, Train Loss 0.4953, Val Loss 0.5472, Time 78.1s\n",
      "================\n",
      "loss CE alpha 0.001263459661822708\n",
      "loss CE beta 0.23164345268160105\n",
      "================\n",
      "loss mse alpha 0.0013990426654345357\n",
      "loss mse beta 0.2574943463783711\n",
      "Step 53, Train Loss 0.4918, Val Loss 0.5690, Time 79.6s\n",
      "================\n",
      "loss CE alpha 0.0011986816196440486\n",
      "loss CE beta 0.23009518701583148\n",
      "================\n",
      "loss mse alpha 0.0013362604775466024\n",
      "loss mse beta 0.2579172304831445\n",
      "Step 54, Train Loss 0.4905, Val Loss 0.5475, Time 81.2s\n",
      "================\n",
      "loss CE alpha 0.0012153853953350336\n",
      "loss CE beta 0.23002964351326227\n",
      "================\n",
      "loss mse alpha 0.0015557898543193005\n",
      "loss mse beta 0.25994207030162214\n",
      "Step 55, Train Loss 0.4927, Val Loss 0.5253, Time 82.9s\n",
      "================\n",
      "loss CE alpha 0.001022041066426027\n",
      "loss CE beta 0.22661060681566597\n",
      "================\n",
      "loss mse alpha 0.0012632723482965957\n",
      "loss mse beta 0.2517299489118159\n",
      "Step 56, Train Loss 0.4806, Val Loss 0.5411, Time 84.4s\n",
      "================\n",
      "loss CE alpha 0.0010164409366552718\n",
      "loss CE beta 0.2249317510984838\n",
      "================\n",
      "loss mse alpha 0.0013015443975746166\n",
      "loss mse beta 0.2502351355273277\n",
      "Step 57, Train Loss 0.4775, Val Loss 0.5487, Time 85.9s\n",
      "================\n",
      "loss CE alpha 0.0010910024167969823\n",
      "loss CE beta 0.22475201198831202\n",
      "================\n",
      "loss mse alpha 0.001220833001571009\n",
      "loss mse beta 0.24548368146643043\n",
      "Step 58, Train Loss 0.4725, Val Loss 0.5482, Time 87.2s\n",
      "================\n",
      "loss CE alpha 0.0009343689263914712\n",
      "loss CE beta 0.2231916424818337\n",
      "================\n",
      "loss mse alpha 0.0011038615732104518\n",
      "loss mse beta 0.2505952691659331\n",
      "Step 59, Train Loss 0.4758, Val Loss 0.5382, Time 88.6s\n",
      "================\n",
      "loss CE alpha 0.0008421240912866778\n",
      "loss CE beta 0.2229517413303256\n",
      "================\n",
      "loss mse alpha 0.0010329475509934128\n",
      "loss mse beta 0.24480548477731645\n",
      "Step 60, Train Loss 0.4696, Val Loss 0.5220, Time 90.1s\n",
      "================\n",
      "loss CE alpha 0.000871904270570667\n",
      "loss CE beta 0.22040481846779586\n",
      "================\n",
      "loss mse alpha 0.0010141596976609435\n",
      "loss mse beta 0.23693186943419278\n",
      "Step 61, Train Loss 0.4592, Val Loss 0.5183, Time 91.5s\n",
      "================\n",
      "loss CE alpha 0.0007939824206914636\n",
      "loss CE beta 0.21950653120875357\n",
      "================\n",
      "loss mse alpha 0.0009637340903282165\n",
      "loss mse beta 0.23830326185561718\n",
      "Step 62, Train Loss 0.4596, Val Loss 0.5210, Time 92.9s\n",
      "================\n",
      "loss CE alpha 0.0008356965239727287\n",
      "loss CE beta 0.21913482807576656\n",
      "================\n",
      "loss mse alpha 0.001044720097706886\n",
      "loss mse beta 0.24070797064341604\n",
      "Step 63, Train Loss 0.4617, Val Loss 0.5215, Time 94.5s\n",
      "================\n",
      "loss CE alpha 0.0006833014847870799\n",
      "loss CE beta 0.21596994595602154\n",
      "================\n",
      "loss mse alpha 0.0009565855674736667\n",
      "loss mse beta 0.23228688752278687\n",
      "Step 64, Train Loss 0.4499, Val Loss 0.5087, Time 95.9s\n",
      "================\n",
      "loss CE alpha 0.000765469793441298\n",
      "loss CE beta 0.21533263362944127\n",
      "================\n",
      "loss mse alpha 0.0009261656974558719\n",
      "loss mse beta 0.2314410900697112\n",
      "Step 65, Train Loss 0.4485, Val Loss 0.5276, Time 97.4s\n",
      "================\n",
      "loss CE alpha 0.000719796297926223\n",
      "loss CE beta 0.21537148915231227\n",
      "================\n",
      "loss mse alpha 0.0008621060747827869\n",
      "loss mse beta 0.2324931062757969\n",
      "Step 66, Train Loss 0.4494, Val Loss 0.5025, Time 98.8s\n",
      "================\n",
      "loss CE alpha 0.0006019851894961903\n",
      "loss CE beta 0.212750131636858\n",
      "================\n",
      "loss mse alpha 0.000837422798940679\n",
      "loss mse beta 0.22594314431771637\n",
      "Step 67, Train Loss 0.4401, Val Loss 0.5334, Time 100.2s\n",
      "================\n",
      "loss CE alpha 0.0006259485733608016\n",
      "loss CE beta 0.21435028165578843\n",
      "================\n",
      "loss mse alpha 0.0008885191215085797\n",
      "loss mse beta 0.2272581565193832\n",
      "Step 68, Train Loss 0.4431, Val Loss 0.5043, Time 101.8s\n",
      "================\n",
      "loss CE alpha 0.0005760032014222816\n",
      "loss CE beta 0.21260396344587207\n",
      "================\n",
      "loss mse alpha 0.000782084740785649\n",
      "loss mse beta 0.22384638665243983\n",
      "Step 69, Train Loss 0.4378, Val Loss 0.5089, Time 103.4s\n",
      "================\n",
      "loss CE alpha 0.0006335579664664692\n",
      "loss CE beta 0.21277732541784644\n",
      "================\n",
      "loss mse alpha 0.0007551071113994113\n",
      "loss mse beta 0.22899346044287086\n",
      "Step 70, Train Loss 0.4432, Val Loss 0.5110, Time 104.9s\n",
      "================\n",
      "loss CE alpha 0.0004634092387277633\n",
      "loss CE beta 0.2122946348041296\n",
      "================\n",
      "loss mse alpha 0.0007563265178760048\n",
      "loss mse beta 0.23194957035593688\n",
      "Step 71, Train Loss 0.4455, Val Loss 0.5044, Time 106.4s\n",
      "================\n",
      "loss CE alpha 0.00047163529961835593\n",
      "loss CE beta 0.21031887652352452\n",
      "================\n",
      "loss mse alpha 0.000674348474785802\n",
      "loss mse beta 0.22877801703289152\n",
      "Step 72, Train Loss 0.4402, Val Loss 0.5062, Time 108.0s\n",
      "================\n",
      "loss CE alpha 0.0004557239210953412\n",
      "loss CE beta 0.20788226956501604\n",
      "================\n",
      "loss mse alpha 0.0006253992662095698\n",
      "loss mse beta 0.22134344480000437\n",
      "Step 73, Train Loss 0.4303, Val Loss 0.5077, Time 109.6s\n",
      "================\n",
      "loss CE alpha 0.0004754765724101162\n",
      "loss CE beta 0.20896656773984432\n",
      "================\n",
      "loss mse alpha 0.0008592698424763512\n",
      "loss mse beta 0.22022891165688635\n",
      "Step 74, Train Loss 0.4305, Val Loss 0.5081, Time 111.0s\n",
      "================\n",
      "loss CE alpha 0.000379496919686062\n",
      "loss CE beta 0.20717002544552088\n",
      "================\n",
      "loss mse alpha 0.0006230639835848705\n",
      "loss mse beta 0.22207373594865204\n",
      "Step 75, Train Loss 0.4302, Val Loss 0.4940, Time 112.5s\n",
      "================\n",
      "loss CE alpha 0.00041582601670597796\n",
      "loss CE beta 0.20637489752843977\n",
      "================\n",
      "loss mse alpha 0.0006175285663630348\n",
      "loss mse beta 0.21651966562494634\n",
      "Step 76, Train Loss 0.4239, Val Loss 0.4977, Time 114.2s\n",
      "================\n",
      "loss CE alpha 0.00039261204274225746\n",
      "loss CE beta 0.20452231680974364\n",
      "================\n",
      "loss mse alpha 0.0006405307965906104\n",
      "loss mse beta 0.21343687153421342\n",
      "Step 77, Train Loss 0.4190, Val Loss 0.5187, Time 115.6s\n",
      "================\n",
      "loss CE alpha 0.00040528440977141147\n",
      "loss CE beta 0.2036154456436634\n",
      "================\n",
      "loss mse alpha 0.0005624222005280899\n",
      "loss mse beta 0.2128593422938138\n",
      "Step 78, Train Loss 0.4174, Val Loss 0.4868, Time 117.0s\n",
      "================\n",
      "loss CE alpha 0.00037749478296973394\n",
      "loss CE beta 0.20137953730300068\n",
      "================\n",
      "loss mse alpha 0.0005228955415077507\n",
      "loss mse beta 0.21101343454793095\n",
      "Step 79, Train Loss 0.4133, Val Loss 0.5361, Time 118.5s\n",
      "================\n",
      "loss CE alpha 0.00030719681844857403\n",
      "loss CE beta 0.20447186967357994\n",
      "================\n",
      "loss mse alpha 0.0005581681161856977\n",
      "loss mse beta 0.22312954873777927\n",
      "Step 80, Train Loss 0.4285, Val Loss 0.5428, Time 119.9s\n",
      "================\n",
      "loss CE alpha 0.00029036364112471346\n",
      "loss CE beta 0.2010966518893838\n",
      "================\n",
      "loss mse alpha 0.00048403582695755176\n",
      "loss mse beta 0.21055381167680026\n",
      "Step 81, Train Loss 0.4124, Val Loss 0.5042, Time 121.4s\n",
      "================\n",
      "loss CE alpha 0.00028983842275920324\n",
      "loss CE beta 0.19807916963472963\n",
      "================\n",
      "loss mse alpha 0.0004686279335146537\n",
      "loss mse beta 0.20777550064958633\n",
      "Step 82, Train Loss 0.4066, Val Loss 0.4807, Time 122.8s\n",
      "================\n",
      "loss CE alpha 0.0003337682841447531\n",
      "loss CE beta 0.20077661508694292\n",
      "================\n",
      "loss mse alpha 0.00047650868837081364\n",
      "loss mse beta 0.20836090426892043\n",
      "Step 83, Train Loss 0.4099, Val Loss 0.5122, Time 124.2s\n",
      "================\n",
      "loss CE alpha 0.0002788800798953162\n",
      "loss CE beta 0.19980728738009929\n",
      "================\n",
      "loss mse alpha 0.0005291450182994595\n",
      "loss mse beta 0.20616362227592616\n",
      "Step 84, Train Loss 0.4068, Val Loss 0.5262, Time 125.9s\n",
      "================\n",
      "loss CE alpha 0.0002539527559747512\n",
      "loss CE beta 0.1992821919731796\n",
      "================\n",
      "loss mse alpha 0.0004064943470439175\n",
      "loss mse beta 0.21095408415421843\n",
      "Step 85, Train Loss 0.4109, Val Loss 0.4845, Time 127.4s\n",
      "================\n",
      "loss CE alpha 0.0002937308334367117\n",
      "loss CE beta 0.19846786595880986\n",
      "================\n",
      "loss mse alpha 0.0004062011736095883\n",
      "loss mse beta 0.20620771409012378\n",
      "Step 86, Train Loss 0.4054, Val Loss 0.5028, Time 128.9s\n",
      "================\n",
      "loss CE alpha 0.00025987594162870666\n",
      "loss CE beta 0.19562601195648313\n",
      "================\n",
      "loss mse alpha 0.0003661636734250351\n",
      "loss mse beta 0.2067650391254574\n",
      "Step 87, Train Loss 0.4030, Val Loss 0.4726, Time 130.4s\n",
      "================\n",
      "loss CE alpha 0.00024135307230608306\n",
      "loss CE beta 0.196814445219934\n",
      "================\n",
      "loss mse alpha 0.0003436409177083988\n",
      "loss mse beta 0.21414693233091384\n",
      "Step 88, Train Loss 0.4115, Val Loss 0.4687, Time 131.9s\n",
      "================\n",
      "loss CE alpha 0.00023069735098033562\n",
      "loss CE beta 0.1967591137625277\n",
      "================\n",
      "loss mse alpha 0.00035354390711290763\n",
      "loss mse beta 0.20786900571547448\n",
      "Step 89, Train Loss 0.4052, Val Loss 0.4682, Time 133.6s\n",
      "================\n",
      "loss CE alpha 0.00021633651576848933\n",
      "loss CE beta 0.1940162534825504\n",
      "================\n",
      "loss mse alpha 0.0003881539450958371\n",
      "loss mse beta 0.19974236246198415\n",
      "Step 90, Train Loss 0.3944, Val Loss 0.4864, Time 135.1s\n",
      "================\n",
      "loss CE alpha 0.0002193914423514798\n",
      "loss CE beta 0.19423989835195243\n",
      "================\n",
      "loss mse alpha 0.000292271152829926\n",
      "loss mse beta 0.2027763000689447\n",
      "Step 91, Train Loss 0.3975, Val Loss 0.4707, Time 136.8s\n",
      "================\n",
      "loss CE alpha 0.00021642532428813865\n",
      "loss CE beta 0.1913605366833508\n",
      "================\n",
      "loss mse alpha 0.0002970190209452994\n",
      "loss mse beta 0.19717928101308643\n",
      "Step 92, Train Loss 0.3891, Val Loss 0.4720, Time 138.4s\n",
      "================\n",
      "loss CE alpha 0.0002160066471333266\n",
      "loss CE beta 0.19151305323466658\n",
      "================\n",
      "loss mse alpha 0.00031406410798808795\n",
      "loss mse beta 0.19868751117028297\n",
      "Step 93, Train Loss 0.3907, Val Loss 0.4965, Time 139.9s\n",
      "================\n",
      "loss CE alpha 0.00019569448513721\n",
      "loss CE beta 0.19172416334040462\n",
      "================\n",
      "loss mse alpha 0.00030267459205788325\n",
      "loss mse beta 0.20274972985498607\n",
      "Step 94, Train Loss 0.3950, Val Loss 0.4770, Time 141.3s\n",
      "================\n",
      "loss CE alpha 0.00017528712992316288\n",
      "loss CE beta 0.18877751678228377\n",
      "================\n",
      "loss mse alpha 0.00027296796633891063\n",
      "loss mse beta 0.19482334905769677\n",
      "Step 95, Train Loss 0.3840, Val Loss 0.4869, Time 142.8s\n",
      "================\n",
      "loss CE alpha 0.00018542375150900625\n",
      "loss CE beta 0.18922323663718998\n",
      "================\n",
      "loss mse alpha 0.00024153958656825125\n",
      "loss mse beta 0.19877499395515769\n",
      "Step 96, Train Loss 0.3884, Val Loss 0.4964, Time 144.1s\n",
      "================\n",
      "loss CE alpha 0.00016563970548304495\n",
      "loss CE beta 0.19042073134332896\n",
      "================\n",
      "loss mse alpha 0.0002488509697286645\n",
      "loss mse beta 0.19956698529422284\n",
      "Step 97, Train Loss 0.3904, Val Loss 0.4817, Time 145.6s\n",
      "================\n",
      "loss CE alpha 0.00017038118608070363\n",
      "loss CE beta 0.19122137404046952\n",
      "================\n",
      "loss mse alpha 0.00026369902188889683\n",
      "loss mse beta 0.19858045247383416\n",
      "Step 98, Train Loss 0.3902, Val Loss 0.5346, Time 147.2s\n",
      "================\n",
      "loss CE alpha 0.0001714534204438678\n",
      "loss CE beta 0.1910666166804731\n",
      "================\n",
      "loss mse alpha 0.0002592025803096476\n",
      "loss mse beta 0.2035149939591065\n",
      "Step 99, Train Loss 0.3950, Val Loss 0.5018, Time 148.6s\n",
      "================\n",
      "loss CE alpha 0.00014092868655097847\n",
      "loss CE beta 0.19983545783907175\n",
      "================\n",
      "loss mse alpha 0.0002406617457381799\n",
      "loss mse beta 0.22568010594695806\n",
      "Step 100, Train Loss 0.4259, Val Loss 0.4737, Time 150.0s\n"
     ]
    }
   ],
   "source": [
    "aBatch = 1000\n",
    "aHidden = 32\n",
    "\n",
    "train_loader = DataLoader(train_dataset,shuffle=False,batch_size=aBatch)\n",
    "val_loader = DataLoader(val_dataset,shuffle=False,batch_size=aBatch)\n",
    "rnn = GRU_RNN_TWO(\n",
    "              input_size=INPUT_SIZE,\n",
    "              hidden_size=aHidden,\n",
    "              num_of_layers=1,\n",
    "              num_alpha_embedding=num_alpha_embedding,\n",
    "              num_beta_embedding=num_beta_embedding,\n",
    "              dropout=0.2\n",
    "             ) \n",
    "\n",
    "rnn, loss_train, loss_val = train_model_two(rnn, train_loader, val_loader, 100, '_alphastat_03') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "48113172",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='Epoch Number', ylabel='Validation Loss'>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 550x250 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 550x250 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot training and validation loss in each epoch\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Initialize figure\n",
    "plt.figure(figsize=(5.5, 2.5))\n",
    "plt.xlabel('Epoch Number', size=16)\n",
    "plt.ylabel('Train Loss', size=16)\n",
    "\n",
    "# Line plot for training loss\n",
    "sns.lineplot(x=np.arange(100), y=loss_train,\n",
    "                 color='#1761B0')\n",
    "\n",
    "# Initialize figure\n",
    "plt.figure(figsize=(5.5, 2.5))\n",
    "plt.xlabel('Epoch Number', size=16)\n",
    "plt.ylabel('Validation Loss', size=16)\n",
    "\n",
    "# Line plot for validation loss\n",
    "sns.lineplot(x=np.arange(100), y=loss_val,\n",
    "                 color='#1761B0')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
