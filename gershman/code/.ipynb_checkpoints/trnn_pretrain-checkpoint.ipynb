{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e92ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "import time\n",
    "import random\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d88b2d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRU_RNN_TWO(nn.Module):\n",
    "        \n",
    "    def __init__(self,input_size, hidden_size, num_of_layers,\n",
    "                 num_beta_embedding, num_gamma_embedding, output_size, dropout):\n",
    "        \n",
    "        super(GRU_RNN_TWO, self).__init__()\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.num_beta_embedding = num_beta_embedding\n",
    "        self.num_gamma_embedding = num_gamma_embedding\n",
    "        \n",
    "        \n",
    "        self.hidden_0 = nn.GRU(  \n",
    "                    input_size=input_size,\n",
    "                    hidden_size=hidden_size,\n",
    "                    num_layers=num_of_layers,\n",
    "                    batch_first=True,\n",
    "                    dropout=dropout\n",
    "        )\n",
    "        \n",
    "        self.hidden_1 = nn.GRU(  \n",
    "                    input_size=input_size + num_beta_embedding + num_gamma_embedding,\n",
    "                    hidden_size=hidden_size,\n",
    "                    num_layers=num_of_layers,\n",
    "                    batch_first=True,\n",
    "                    dropout=dropout \n",
    "        )\n",
    "    \n",
    "    \n",
    "        self.out_beta = nn.Linear(hidden_size, num_beta_embedding)\n",
    "        self.out_gamma = nn.Linear(hidden_size, num_gamma_embedding)\n",
    "        \n",
    "        self.relu_beta = nn.ReLU()\n",
    "        self.relu_gamma = nn.ReLU()\n",
    "\n",
    "        self.reg_beta = nn.Linear(num_beta_embedding, 1)\n",
    "        self.reg_gamma = nn.Linear(num_gamma_embedding, 1)\n",
    "        \n",
    "        self.out_action = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "\n",
    "        # parameters estimation\n",
    "        output_0, hn_0 = self.hidden_0(x)\n",
    "        \n",
    "        output_beta = self.out_beta(output_0)\n",
    "        output_beta = self.relu_beta(output_beta)\n",
    "        \n",
    "        output_gamma = self.out_gamma(output_0)\n",
    "        output_gamma = self.relu_gamma(output_gamma)\n",
    "        \n",
    "        cont_output_beta = self.reg_beta(output_beta)\n",
    "        cont_output_gamma = self.reg_gamma(output_gamma)\n",
    "    \n",
    "        # concat input \n",
    "        input_1 = torch.concat([x[0],output_beta[0],output_gamma[0]],dim=1) # cat\n",
    "        input_1 = input_1.reshape(1,x.shape[1],self.input_size + self.num_beta_embedding + self.num_gamma_embedding)\n",
    "        \n",
    "        # action predication\n",
    "        output_action, hn_1 = self.hidden_1(input_1)\n",
    "        output_action = self.out_action(output_action)\n",
    "        output_action = F.softmax(output_action,dim=-1)\n",
    "\n",
    "        return output_beta, output_gamma, cont_output_beta, cont_output_gamma, output_action, hn_0, hn_1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccca69bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class behavior_dataset(Dataset):\n",
    "    \"\"\"         \n",
    "    \"\"\"\n",
    "    def __init__(self,dataframe):\n",
    "        \n",
    "        # action one hot transformation \n",
    "        action = np.array(dataframe['action'])\n",
    "        if np.all(action == action[0]):\n",
    "            action = np.append(action,(1-action[0]))\n",
    "            action = torch.tensor((action).reshape(len(dataframe) + 1),dtype=int)\n",
    "            action_onehot = nn.functional.one_hot(action, len(action.unique()))\n",
    "            # delete last one\n",
    "            action_onehot = action_onehot[:-1]\n",
    "        else:\n",
    "            action = torch.tensor((action).reshape(len(dataframe)),dtype=int)\n",
    "            action_onehot = nn.functional.one_hot(action, len(action.unique()))\n",
    "        \n",
    "        # reward\n",
    "        reward = torch.tensor((np.array(dataframe['reward'])).reshape(len(dataframe)),dtype=int)\n",
    "        \n",
    "        # concatinating reward and action\n",
    "        reward_action = torch.cat([reward[ :, np.newaxis], action_onehot],1)\n",
    "        \n",
    "        # adding dummy zeros to the beginning and ignoring the last one\n",
    "        reward_action_shift = nn.functional.pad(reward_action,[0,0,1,0])[:-1]\n",
    "        \n",
    "        n_blocks = int(len(dataframe)/10) \n",
    "        reward_action_shift.reshape(n_blocks,10,INPUT_SIZE)[:,0,:] = torch.zeros(size=(n_blocks,INPUT_SIZE))\n",
    "\n",
    "        # parameters one hot transformation \n",
    "        dis_beta = torch.tensor((np.array(dataframe['beta_categorical'])).reshape(len(dataframe)),dtype=int)\n",
    "        dis_beta = dis_beta.type(dtype=torch.float32)\n",
    "        \n",
    "        # parameters one hot transformation \n",
    "        dis_gamma = torch.tensor((np.array(dataframe['gamma_categorical'])).reshape(len(dataframe)),dtype=int)\n",
    "        dis_gamma = dis_gamma.type(dtype=torch.float32)\n",
    "        \n",
    "        cont_beta = torch.tensor((np.array(dataframe['beta'])).reshape(len(dataframe)),dtype=torch.float32)\n",
    "        cont_gamma = torch.tensor((np.array(dataframe['gamma'])).reshape(len(dataframe)),dtype=torch.float32)\n",
    "        \n",
    "        # network input \n",
    "        x = reward_action_shift\n",
    "        \n",
    "        # network output \n",
    "        y = torch.cat([action_onehot, dis_beta[ :, np.newaxis], dis_gamma[ :, np.newaxis],\n",
    "                       cont_beta[ :, np.newaxis], cont_gamma[ :, np.newaxis],\n",
    "                      ],1)\n",
    "  \n",
    "        self.x = x.type(dtype=torch.float32)\n",
    "        self.y = y.type(dtype=torch.float32)\n",
    "        self.len = len(dataframe)\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        return self.x[idx],self.y[idx]\n",
    "  \n",
    "    def __len__(self):\n",
    "        return self.len    \n",
    "    \n",
    "class merge_behavior_dataset(Dataset):\n",
    "    \"\"\" \n",
    "    Merge Dataset of each agent to one dataset\n",
    "    \n",
    "    Args:\n",
    "        dataset_list: list of Dataset of all agent \n",
    "        n_trials: num_of_trials each agent was simulated\n",
    "        \n",
    "    Returns: \n",
    "        torch Dataset:\n",
    "        x: [reward_(t-1) , action_(t-1)] all agents\n",
    "        y: [action_t, parameter embedding] all agents\n",
    "        \n",
    "    \"\"\"\n",
    "    def __init__(self, dataset_list, n_trials):\n",
    "        X = []\n",
    "        Y = []\n",
    "        for agent in dataset_list:\n",
    "            for i in range(n_trials):\n",
    "                X.append(agent[i][0])\n",
    "                Y.append(agent[i][1])\n",
    "                \n",
    "        self.x = torch.stack(X).type(dtype=torch.float32)\n",
    "        self.y = torch.stack(Y).type(dtype=torch.float32)\n",
    "        self.len = len(X)   \n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        return self.x[idx],self.y[idx]\n",
    "  \n",
    "    def __len__(self):\n",
    "        return self.len    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ebbb110",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_two(net, train_loader, val_loader ,epochs, name):\n",
    "        \n",
    "    min_loss_t = 100\n",
    "    min_loss_v = 100\n",
    "        \n",
    "    # array to track loss \n",
    "    train_loss_array , val_loss_array = [], []\n",
    "    \n",
    "    # move net to GPU\n",
    "    net.to(device)\n",
    "\n",
    "    # Use Adam optimizer\n",
    "    optimizer = optim.Adam(net.parameters(), lr=0.001) \n",
    "    \n",
    "    # start timer\n",
    "    start_time = time.time()   \n",
    "    \n",
    "    # Loop over epochs \n",
    "    for i in range(epochs):        \n",
    "        # Randomize train batch example \n",
    "        train_loader = random.sample(list(train_loader), len(train_loader))\n",
    "      \n",
    "        running_loss = 0\n",
    "        \n",
    "        run_action, run_d_beta, run_d_gamma = 0,0,0\n",
    "        run_c_beta, run_c_gamma = 0,0\n",
    "        # Loop over training batches\n",
    "        for j, (X, y_true) in enumerate(train_loader):\n",
    "    \n",
    "            X, y_true = X.to(device), y_true.to(device) # move to GPU\n",
    "            X = X.reshape(1,X.shape[0],INPUT_SIZE) # reshape to  1 x trials x input_size\n",
    "            \n",
    "            optimizer.zero_grad()  # zero the gradient buffers\n",
    "            \n",
    "            y_hat_dis_beta, y_hat_dis_gamma, y_hat_cont_beta, y_hat_cont_gamma, y_hat_action, _, _  = net(X) # forward pass\n",
    "            \n",
    "            y_hat_action = (y_hat_action.view(-1, num_of_action)) # Reshape to (SeqLen x Batch, OutputSize)\n",
    "            y_hat_dis_beta = (y_hat_dis_beta.view(-1, num_beta_embedding)) # Reshape to (SeqLen x Batch, OutputSize)\n",
    "            y_hat_dis_gamma = (y_hat_dis_gamma.view(-1, num_gamma_embedding)) # Reshape to (SeqLen x Batch, OutputSize)\n",
    "        \n",
    "            y_hat_cont_beta = (y_hat_cont_beta.view(-1)) # Reshape to (SeqLen x Batch, OutputSize)\n",
    "            y_hat_cont_gamma = (y_hat_cont_gamma.view(-1)) # Reshape to (SeqLen x Batch, OutputSize)\n",
    "\n",
    "            loss, l_action, l_dis_beta, l_dis_gamma, l_cont_beta, l_cont_gamma = multi_loss(\n",
    "                                                                                            y_hat_action,\n",
    "                                                                                            y_hat_dis_beta,\n",
    "                                                                                            y_hat_dis_gamma,\n",
    "                                                                                            y_hat_cont_beta,\n",
    "                                                                                            y_hat_cont_gamma,\n",
    "                                                                                            y_true) # compute loss\n",
    "            \n",
    "            loss.backward() # backprop the loss\n",
    "            optimizer.step() # update the weights \n",
    "            running_loss += loss.item()\n",
    "            \n",
    "            run_action += l_action.item()\n",
    "            \n",
    "            run_d_beta += l_dis_beta.item()\n",
    "            run_d_gamma += l_dis_gamma.item()\n",
    "            \n",
    "            run_c_beta += l_cont_beta.item()\n",
    "            run_c_gamma += l_cont_gamma.item()\n",
    "            \n",
    "        train_loss_array.append(running_loss/len(train_loader))\n",
    "        loss = eval_net_two(net,val_loader)\n",
    "        val_loss_array.append(loss)\n",
    "                \n",
    "        print('================')\n",
    "        print('loss BCE action',(run_action/len(train_loader)))\n",
    "        \n",
    "        print('================')\n",
    "        print('loss CE beta',(run_d_beta/len(train_loader)))\n",
    "        print('loss CE gamma',(run_c_gamma/len(train_loader)))\n",
    "        \n",
    "        print('================')\n",
    "        print('loss mse beta',(run_c_beta/len(train_loader)))\n",
    "        print('loss mse gamma',(run_c_gamma/len(train_loader)))\n",
    "        \n",
    "\n",
    "        if train_loss_array[i] <= min_loss_t:\n",
    "            checkpoint = {'epoch':i+1,'model_state':net.state_dict(),\n",
    "                          'optim_state':optimizer.state_dict(),'loss':train_loss_array[i]}\n",
    "            torch.save(checkpoint,f'10_models/checkpoint_best_train_{name}.pth')\n",
    "\n",
    "            min_loss_t = train_loss_array[i]\n",
    "\n",
    "        if val_loss_array[i] <= min_loss_v:\n",
    "            checkpoint = {'epoch':i+1,'model_state':net.state_dict(),\n",
    "                          'optim_state':optimizer.state_dict(),'loss':val_loss_array[i]}\n",
    "            torch.save(checkpoint,f'10_models/checkpoint_best_val_{name}.pth')\n",
    "\n",
    "            min_loss_v = val_loss_array[i]\n",
    "\n",
    "        print('Step {}, Train Loss {:0.4f}, Val Loss {:0.4f}, Time {:0.1f}s'.format(i+1,\n",
    "                                                                                    train_loss_array[i],\n",
    "                                                                                    val_loss_array[i],\n",
    "                                                                                    time.time() - start_time))\n",
    "\n",
    "                \n",
    "\n",
    "        net.train()\n",
    "\n",
    "            \n",
    "    return net, train_loss_array , val_loss_array "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1b9c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_net_two(net, val_loader):\n",
    "    with torch.no_grad():\n",
    "        net.eval()\n",
    "        running_loss = 0\n",
    "        for j, (X, y_true) in enumerate(val_loader):\n",
    "            \n",
    "            X, y_true = X.to(device), y_true.to(device) # move to GPU\n",
    "            X = X.reshape(1,X.shape[0],INPUT_SIZE) # reshape to  1 x trials x input_size\n",
    "            \n",
    "            y_hat_dis_beta, y_hat_dis_gamma, y_hat_cont_beta, y_hat_cont_gamma, y_hat_action, _, _ = net(X) # forward pass\n",
    "            \n",
    "            y_hat_action = (y_hat_action.view(-1, num_of_action)) # Reshape to (SeqLen x Batch, OutputSize)\n",
    "            y_hat_dis_beta = (y_hat_dis_beta.view(-1, num_beta_embedding)) # Reshape to (SeqLen x Batch, OutputSize)\n",
    "            y_hat_dis_gamma = (y_hat_dis_gamma.view(-1, num_gamma_embedding)) # Reshape to (SeqLen x Batch, OutputSize)\n",
    "        \n",
    "            y_hat_cont_beta = (y_hat_cont_beta.view(-1)) # Reshape to (SeqLen x Batch, OutputSize)\n",
    "            y_hat_cont_gamma = (y_hat_cont_gamma.view(-1)) # Reshape to (SeqLen x Batch, OutputSize)\n",
    "\n",
    "            loss, l_action, l_dis_beta, l_dis_gamma, l_cont_beta, l_cont_gamma = multi_loss(\n",
    "                                    y_hat_action,\n",
    "                                    y_hat_dis_beta,\n",
    "                                    y_hat_dis_gamma,\n",
    "                                    y_hat_cont_beta,\n",
    "                                    y_hat_cont_gamma,\n",
    "                                    y_true) # compute loss\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "    \n",
    "    return (running_loss/len(val_loader))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e0c365e",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = f'../data/artificial_trainset_10_000.csv'\n",
    "df = pd.read_csv(path)\n",
    "\n",
    "# define constant \n",
    "num_of_action = df['action'].nunique()\n",
    "num_of_trials = df['trial'].nunique()*df['block'].nunique()\n",
    "num_of_agents = df['agent'].nunique()\n",
    "num_beta_embedding = df['beta_categorical'].nunique()\n",
    "num_gamma_embedding = df['gamma_categorical'].nunique()\n",
    "\n",
    "# netowrk input and output dimension  \n",
    "INPUT_SIZE = 1 + num_of_action\n",
    "OUTPUT_SIZE = num_of_action\n",
    "\n",
    "# train val test split \n",
    "n_agent_train = int(0.8*num_of_agents)\n",
    "n_agent_val = int(0.2*num_of_agents)\n",
    "\n",
    "all_data = []\n",
    "for i in range(num_of_agents):\n",
    "    s = i*num_of_trials\n",
    "    e = (i+1)*num_of_trials\n",
    "    cur_df = df.iloc[s:e]\n",
    "    cur_df = cur_df.reset_index()\n",
    "    all_data.append([i,behavior_dataset(cur_df)])\n",
    "\n",
    "random.shuffle(all_data)\n",
    "all_data = np.array(all_data)\n",
    "train_dataset = all_data[:n_agent_train,1]\n",
    "train_dataset = merge_behavior_dataset(train_dataset,num_of_trials)\n",
    "\n",
    "val_dataset = all_data[n_agent_train:,1]\n",
    "val_dataset = merge_behavior_dataset(val_dataset,num_of_trials)\n",
    "val_agents = np.array([all_data[i,0] for i in range(n_agent_train,num_of_agents)])\n",
    "    \n",
    "print('num_of_trials:',num_of_trials)\n",
    "print('num_of_agents:',num_of_agents)\n",
    "print('num_beta_embedding:',num_beta_embedding)\n",
    "print('num_gamma_embedding:',num_gamma_embedding)\n",
    "print('train_size:', n_agent_train*num_of_trials)\n",
    "\n",
    "# print('train_size:', train_dataset[:][0].shape)\n",
    "# print('val_size:', n_agent_val*num_of_trials)\n",
    "# print('val_size:', val_dataset[:][0].shape)\n",
    "# print('val_agents',val_agents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd1401a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_loss(y_hat_action, y_hat_dis_beta, y_hat_dis_gamma, y_hat_cont_beta, y_hat_cont_gamma, y_true):\n",
    "    \n",
    "    # slice true action and true parameters embedding \n",
    "    y_true_action = y_true[:,:2]\n",
    "    \n",
    "    y_true_dis_beta = torch.flatten(y_true[:,2])\n",
    "    y_true_dis_beta = y_true_dis_beta.type(dtype=torch.LongTensor).to(device)\n",
    "    \n",
    "    y_true_dis_gamma = torch.flatten(y_true[:,3])\n",
    "    y_true_dis_gamma = y_true_dis_gamma.type(dtype=torch.LongTensor).to(device)\n",
    "    \n",
    "    y_true_cont_beta =  y_true[:,4]\n",
    "    y_true_cont_gamma =  y_true[:,5]\n",
    "    \n",
    "    # define losses\n",
    "    criterion0 = nn.BCELoss()\n",
    "    criterion1 = nn.CrossEntropyLoss()\n",
    "    criterion2 = nn.MSELoss()\n",
    "    \n",
    "    l_action = criterion0(y_hat_action, y_true_action)\n",
    "    l_dis_beta = criterion1(y_hat_dis_beta, y_true_dis_beta)\n",
    "    l_dis_gamma = criterion1(y_hat_dis_gamma, y_true_dis_gamma)\n",
    "    \n",
    "    l_cont_beta = criterion2(y_hat_cont_beta,y_true_cont_beta)\n",
    "    l_cont_gamma = criterion2(y_hat_cont_gamma,y_true_cont_gamma)\n",
    "\n",
    "    # combine losses\n",
    "    total_loss = 1*l_action + 0.5*l_dis_beta + 0.25*l_dis_gamma + 1*l_cont_beta + 10*l_cont_gamma \n",
    "    \n",
    "    return total_loss, 1*l_action, 0.5*l_dis_beta, 0.25*l_dis_gamma , 1*l_cont_beta , 10*l_cont_gamma "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4acb9428",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "aBatch = 1000\n",
    "aHidden = 32\n",
    "\n",
    "train_loader = DataLoader(train_dataset,shuffle=False,batch_size=aBatch)\n",
    "val_loader = DataLoader(val_dataset,shuffle=False,batch_size=aBatch)\n",
    "rnn = GRU_RNN_TWO(\n",
    "              input_size=INPUT_SIZE,\n",
    "              hidden_size=aHidden,\n",
    "              num_of_layers=1,\n",
    "              num_beta_embedding=num_beta_embedding,\n",
    "              num_gamma_embedding=num_gamma_embedding,\n",
    "              output_size=OUTPUT_SIZE,\n",
    "              dropout=0.2\n",
    "             ) \n",
    "\n",
    "rnn, loss_train, loss_val = train_model_two(rnn, train_loader, val_loader, 100, 0)  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
